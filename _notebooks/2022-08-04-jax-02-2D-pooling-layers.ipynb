{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cross-navigation",
   "metadata": {},
   "source": [
    "# Two Dimensional Pooling Layers\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: [jax, pooling]\n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-nickname",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the style of my last post on 2D convolutional layers, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-defeat",
   "metadata": {},
   "source": [
    "## Purpose of Pooling Layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-opportunity",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "For now, I only need numpy and tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "isolated-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-ending",
   "metadata": {},
   "source": [
    "## Implementation from First Principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "swiss-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "phantom-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_images(input_batch, pool_size, strides, pool_fn=np.max):\n",
    "    batch_size, xm, xn, num_channels  = input_batch.shape \n",
    "    \n",
    "    pm, pn = pool_size \n",
    "    sm, sn = strides\n",
    "    \n",
    "    ym, yn = 1 + ((xm - pm)//sm), 1 + ((xn - pn)//sn) \n",
    "    y = np.zeros((batch_size, ym, yn, num_channels))\n",
    "\n",
    "    for iy, ix in enumerate(range(0, xm-pm+1, sm)):\n",
    "        for jy, jx in enumerate(range(0, xn-pn+1, sn)):\n",
    "            y[:, iy, jy, :] = pool_fn(\n",
    "                input_batch[:, ix:ix+pm, jx:jx+pn, :],\n",
    "                axis=(1,2)\n",
    "            )         \n",
    "    return y    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-short",
   "metadata": {},
   "source": [
    "## Compare to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "catholic-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keras = tf.keras.layers.MaxPool2D( \n",
    "    pool_size=(4, 4), \n",
    "    strides=(2,2),\n",
    "    padding='valid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "focused-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = np.random.randn(32,28,28,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "secret-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch_keras = layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "tutorial-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch_numpy = downsample_images(\n",
    "    input_batch, \n",
    "    pool_size=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    "    pool_fn = np.max\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-texas",
   "metadata": {},
   "source": [
    "To check that the Keras output and numpy outputs are approximately equal, I make sure that the absolute error is below a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "latter-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.max(np.abs(output_batch_keras - output_batch_numpy)) < 1e-16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-westminster",
   "metadata": {},
   "source": [
    "Although the outputs are about the same, the Keras version runs much faster, as the following benchmarks show.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "adjusted-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.61 ms ± 47.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "downsample_images(\n",
    "    input_batch, \n",
    "    pool_size=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "employed-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666 µs ± 52.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-former",
   "metadata": {},
   "source": [
    "### Pooling Layer in JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "finnish-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from typing import Tuple, List, Callable\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "vertical-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D: \n",
    "    pool_shape: Tuple[int,int]\n",
    "    strides: Tuple[int,int]\n",
    "    padding: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-slovenia",
   "metadata": {},
   "source": [
    "#### Constructor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "growing-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __init__(\n",
    "    self: MaxPool2D, \n",
    "    pool_shape=(2,2), \n",
    "    strides=(1,1), \n",
    "    padding='valid'):\n",
    "    \n",
    "    self.pool_shape = pool_shape\n",
    "    self.strides = strides \n",
    "    self.padding = padding\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-carol",
   "metadata": {},
   "source": [
    "#### `__call__` Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-sweet",
   "metadata": {},
   "source": [
    "To implement `__call__` we use the JAX builtin function `conv_general_dilated`.  Except for the `dimension_numbers` argument, it's pretty easy to figure out what it's doing (but I'm still not clear on how it works - maybe save that for another post).  Like the Keras `Conv2D` layer, it has additional input arguments that give you further control over the convolution.  I'm not including these additional arguments here because I'm trying to keep things as simple as possible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "contrary-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __call__(self: MaxPool2D, batch: jnp.ndarray):\n",
    "    \n",
    "    pool_shape = (1, ) + self.pool_shape + (1, )\n",
    "    strides = (1, ) + self.strides + (1, ) \n",
    "    outputs = jax.lax.reduce_window(\n",
    "        batch,\n",
    "        -jnp.inf,\n",
    "        jax.lax.max,\n",
    "        window_dimensions=pool_shape,\n",
    "        window_strides=strides,\n",
    "        padding=self.padding\n",
    "    )\n",
    "\n",
    "    return outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-motorcycle",
   "metadata": {},
   "source": [
    "#### Adding to pytree Registry\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "neither-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def tree_flatten(self: MaxPool2D) -> Tuple[List[jnp.ndarray], dict]:\n",
    "    params = (None,)\n",
    "    metadata = {k: v for k, v in self.__dict__.items()}\n",
    "    return params, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "injured-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(cls_method=True)\n",
    "def tree_unflatten(cls: MaxPool2D, metadata: dict, params:List[jnp.ndarray]):\n",
    "    # This assumes that each key-value pair in the metadata dict corresponds to a constructor argument.\n",
    "    layer = cls(**metadata)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "close-circle",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Duplicate custom PyTreeDef type registration for <class '__main__.MaxPool2D'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_333426/2773652856.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_pytree_node_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/tree_util.py\u001b[0m in \u001b[0;36mregister_pytree_node_class\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m   \"\"\"\n\u001b[0;32m--> 157\u001b[0;31m   \u001b[0mregister_pytree_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethodcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tree_flatten'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_unflatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/tree_util.py\u001b[0m in \u001b[0;36mregister_pytree_node\u001b[0;34m(nodetype, flatten_func, unflatten_func)\u001b[0m\n\u001b[1;32m    135\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnodetype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m   \u001b[0mpytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munflatten_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m   \u001b[0m_registry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnodetype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RegistryEntry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munflatten_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Duplicate custom PyTreeDef type registration for <class '__main__.MaxPool2D'>."
     ]
    }
   ],
   "source": [
    "_ = jax.tree_util.register_pytree_node_class(MaxPool2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-laptop",
   "metadata": {},
   "source": [
    "## Compare JAX and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "inappropriate-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_jax = Conv2D(\n",
    "    input_channels=layer_keras.input_spec.axes[-1],\n",
    "    output_channels=layer_keras.filters,\n",
    "    filter_shape=layer_keras.kernel_size,\n",
    "    strides=layer_keras.strides,\n",
    "    padding=layer_keras.padding\n",
    ")\n",
    "\n",
    "layer_jax.filters, layer_jax.biases = layer_keras.get_weights()\n",
    "\n",
    "output_batch_jax = layer_jax(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-wages",
   "metadata": {},
   "source": [
    "Because the following assertion passes, we can be reassured that both layers are calculating the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "registered-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.max(np.abs(output_batch_keras - output_batch_jax)) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-myrtle",
   "metadata": {},
   "source": [
    "What about the calculation time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "painful-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 µs ± 8.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "vital-pocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 µs ± 8.89 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "layer_jax(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-folks",
   "metadata": {},
   "source": [
    "Not too bad, the JAX version only about 100 microseconds slower than Keras.  Fortunately, the JAX version can go even faster after applying the `jax.jit` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "artificial-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_jax_jitted = jax.jit(layer_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "infectious-typing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 µs ± 1.78 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "layer_jax_jitted(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-madness",
   "metadata": {},
   "source": [
    "Now it's faster than Keras.  I realize you can't trust micro-benchmarks, but it's good to know that with respect to performance, JAX and Keras seem to be in the same ballpark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-condition",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-brazil",
   "metadata": {},
   "source": [
    "In the post, I implemented the mechanics of a 2D convolutional layer in numpy, from first principles.  After this was proven to be very inefficient compare to Keras, I built a simple layer in JAX and showed that it performed as well as the Keras version on a sample input batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-progress",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9eb3d55570fa83a5d0e75ab0fc9e29d7692aa2022c5c86ae3b4c36003072d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
