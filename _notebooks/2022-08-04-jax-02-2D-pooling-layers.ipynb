{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frequent-rescue",
   "metadata": {},
   "source": [
    "# Two Dimensional Pooling Layers\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: [jax, pooling]\n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-saint",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this post, I'll be implementing a 2D max-pooling layer from scratch and in JAX.  As before, we'll compare each version to Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-valentine",
   "metadata": {},
   "source": [
    "## Purpose of Pooling Layers\n",
    "\n",
    "Pooling layers reduce the number of parameters in convolutional neural networks by downsampling the feature maps generated by the convolutional layers.  Under the hood, they are actually very similar to convolutional layers.  Both layers work by stepping through an input image based on a stride, extracting a chunk of a specified size,  and compressing 3D chunk with some sort of computation.  The main difference between the two layers is the computation.  Recall from the last post that convolutional layers compresses a chunk to a single number by multiplying it's elements with a set of filter coefficients, summing the products, and adding a bias term.  There aren't any filters nor bias terms in pooling layers.  They use simple functions (e.g. `max`, `mean`, etc) that don't depend on any learnable parameters to compress each chunk.  \n",
    "\n",
    "Unlike convolutional layers, pooling layer retain the number of input channels in the input image.  So you can think of these *pooling functions* as being applied to each channel separately and merged back together.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-antenna",
   "metadata": {},
   "source": [
    "## Implementation from First Principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "sticky-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-currency",
   "metadata": {},
   "source": [
    "Here's an implementation of a pooling layer.  You can configure how each chunk gets downsampled by choosing different pooling function, `pool_fn`. Because `pool_fn` is set to `np.max` in the argument list, max-pooling is executed by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "imperial-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_images(input_batch, pool_size, strides, pool_fn=np.max):\n",
    "    batch_size, xm, xn, num_channels  = input_batch.shape \n",
    "    \n",
    "    pm, pn = pool_size \n",
    "    sm, sn = strides\n",
    "    \n",
    "    #ym, yn = 1 + ((xm - pm)//sm), 1 + ((xn - pn)//sn) \n",
    "    ym, yn = 1 + (xm - (pm-1) - 1)/sm,  1 + (xn - (pn-1) - 1)/sn\n",
    "    ym, yn = np.int(np.ceil(ym)), np.int(np.ceil(yn))\n",
    "    y = np.zeros((batch_size, ym, yn, num_channels))\n",
    "\n",
    "    for h, ix in enumerate(range(0, xm-pm+1, sm)):\n",
    "        for w, jx in enumerate(range(0, xn-pn+1, sn)):\n",
    "            chunk = input_batch[:, ix:ix+pm, jx:jx+pn, :]\n",
    "            y[:, h, w, :] = pool_fn(chunk, axis=(1,2))\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-philadelphia",
   "metadata": {},
   "source": [
    "This looks a lot like the convolution functions implemented in the last post.  It extracts a chunk from the 4D array array and executes `pool_fn` for every batch and channel independently. The line\n",
    "```python\n",
    "y[:, h, w, :] = pool_fn(chunk, axis=(1,2))       \n",
    "```\n",
    "takes advantage of numpy's vectorization capabilities.  What this says is that the `pool_fn` is evaluated with respect to the height and width axes As far as the calculation goes, the batch and channel dimensions are ignored, and only serve as place holders for the result.  This means\n",
    "that for each `chunk`, the value `pool_fn(chunk, axis=(1,2))` is a 2D array where the number of rows is equal to the number of items in the batch and the number of columns is equal to the number of channels.\n",
    "\n",
    "Here's a snippet of code that does the same thing, just very slowly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "supported-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    " def slow_max_pool(chunk):\n",
    "    num_items, height, width, num_channels = chunk.shape\n",
    "    result = np.zeros((num_items, num_channels))\n",
    "    for item in range(num_items):\n",
    "        for chan in range(num_channels):\n",
    "            max_val = -np.infty\n",
    "            for h in range(height):\n",
    "                for w in range(width):\n",
    "                    max_val = max(chunk[item, h, w, chan], max_val)\n",
    "            result[item, chan] = max_val\n",
    "    return result\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-lithuania",
   "metadata": {},
   "source": [
    "Just to make sure, let's compare the two versions. We'll define a random chunk, check that the vectorized and non-vectorized chunk-pooling give the same answer, and see how long each one takes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "afraid-furniture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474 µs ± 5.76 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "19.7 ms ± 393 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "chunk = np.random.randn(32, 28, 28, 3)\n",
    "result_vectorized = np.max(chunk, axis=(1,2))\n",
    "result_non_vectorized = slow_max_pool(chunk)\n",
    "\n",
    "assert np.all(np.isclose(result_non_vectorized, result_vectorized, atol=1e-6))\n",
    "\n",
    "%timeit -n 100 np.max(chunk, axis=(1,2))\n",
    "%timeit -n 100 slow_max_pool(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-revolution",
   "metadata": {},
   "source": [
    "No surprise that `slow_max_pool` is significantly slower than the vectorized version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-copyright",
   "metadata": {},
   "source": [
    "## Compare to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "powered-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keras = tf.keras.layers.MaxPool2D( \n",
    "    pool_size=(4, 4), \n",
    "    strides=(2,2),\n",
    "    padding='valid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "committed-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = np.random.randn(32,28,28,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "matched-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch_keras = layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "middle-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch_numpy = downsample_images(\n",
    "    input_batch, \n",
    "    pool_size=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    "    pool_fn = np.max\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-license",
   "metadata": {},
   "source": [
    "To check that the Keras output and numpy outputs are approximately equal, I make sure that the absolute error is below a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "solar-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(output_batch_keras,output_batch_numpy, atol=1e-16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-savage",
   "metadata": {},
   "source": [
    "Although the outputs are about the same, the Keras version runs much faster, as the following benchmarks show.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "alike-report",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.03 ms ± 17.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "downsample_images(\n",
    "    input_batch, \n",
    "    pool_size=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "useful-internet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695 µs ± 41.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-calgary",
   "metadata": {},
   "source": [
    "### Pooling Layer in JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "brazilian-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from typing import Tuple, List, Callable\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "engaged-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D: \n",
    "    pool_shape: Tuple[int,int]\n",
    "    strides: Tuple[int,int]\n",
    "    padding: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-exemption",
   "metadata": {},
   "source": [
    "#### Constructor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "accepting-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __init__(\n",
    "    self: MaxPool2D, \n",
    "    pool_shape=(2,2), \n",
    "    strides=(1,1), \n",
    "    padding='valid'):\n",
    "    \n",
    "    self.pool_shape = pool_shape\n",
    "    self.strides = strides \n",
    "    self.padding = padding\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-circus",
   "metadata": {},
   "source": [
    "#### `__call__` Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "constant-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __call__(self: MaxPool2D, batch: jnp.ndarray):\n",
    "    \n",
    "    outputs = jax.lax.reduce_window(\n",
    "        batch,\n",
    "        -jnp.inf,\n",
    "        jax.lax.max,\n",
    "        window_dimensions=(1, ) + self.pool_shape + (1, ),\n",
    "        window_strides= (1, ) + self.strides + (1, ) ,\n",
    "        padding=self.padding\n",
    "    )\n",
    "\n",
    "    return outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-villa",
   "metadata": {},
   "source": [
    "#### Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "distant-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def tree_flatten(self: MaxPool2D) -> Tuple[List[jnp.ndarray], dict]:\n",
    "    params = (None,)\n",
    "    metadata = {k: v for k, v in self.__dict__.items()}\n",
    "    return params, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "abroad-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(cls_method=True)\n",
    "def tree_unflatten(cls: MaxPool2D, metadata: dict, params:List[jnp.ndarray]):\n",
    "    # This assumes that each key-value pair in the metadata dict corresponds to a constructor argument.\n",
    "    layer = cls(**metadata)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "approved-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = jax.tree_util.register_pytree_node_class(MaxPool2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-pipeline",
   "metadata": {},
   "source": [
    "## Compare JAX and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "veterinary-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_jax = MaxPool2D(\n",
    "    pool_shape=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    "    padding=layer_keras.padding\n",
    ")\n",
    "\n",
    "output_batch_jax = layer_jax(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-entrepreneur",
   "metadata": {},
   "source": [
    "Because the following assertion passes, we can be reassured that both layers are calculating the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "intended-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(output_batch_keras, output_batch_jax, atol=1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-armor",
   "metadata": {},
   "source": [
    "What about the calculation time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "employed-plant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 µs ± 68.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "broadband-sellers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 µs ± 24.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "layer_jax(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-fisher",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9eb3d55570fa83a5d0e75ab0fc9e29d7692aa2022c5c86ae3b4c36003072d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
