{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "improved-martin",
   "metadata": {},
   "source": [
    "# Two Dimensional Pooling Layers\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: [jax, pooling]\n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-analyst",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this post, I'll be implementing a 2D max-pooling layer from scratch and in JAX.  As before, we'll compare each version to Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-franchise",
   "metadata": {},
   "source": [
    "## Purpose of Pooling Layers\n",
    "\n",
    "Pooling layers reduce the number of parameters in convolutional neural networks by downsampling the feature maps generated by the convolutional layers.  Under the hood, they are actually very similar to convolutional layers.  Both layers work by stepping through an input image based on a stride, extracting a chunk of a specified size,  and compressing 3D chunk with some sort of computation.  The main difference between the two layers is the computation.  Recall from the last post that convolutional layers compresses a chunk to a single number by multiplying it's elements with a set of filter coefficients, summing the products, and adding a bias term.  There aren't any filters nor bias terms in pooling layers.  They use simple functions (e.g. `max`, `mean`, etc) that don't depend on any learnable parameters to compress each chunk.  \n",
    "\n",
    "Unlike convolutional layers, pooling layer retain the number of input channels in the input image.  So you can think of these *pooling functions* as being applied to each channel separately and merged back together.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-christmas",
   "metadata": {},
   "source": [
    "## Implementation from First Principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-gamma",
   "metadata": {},
   "source": [
    "Here's an implementation of a pooling layer.  You can configure how each chunk gets downsampled by choosing different pooling function, `pool_fn`. Because `pool_fn` is set to `np.max` in the argument list, max-pooling is executed by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "rational-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_images(input_batch, pool_size, strides, pool_fn=np.max):\n",
    "    batch_size, xm, xn, num_channels  = input_batch.shape \n",
    "    \n",
    "    pm, pn = pool_size \n",
    "    sm, sn = strides\n",
    "    \n",
    "    #ym, yn = 1 + ((xm - pm)//sm), 1 + ((xn - pn)//sn) \n",
    "    ym, yn = 1 + (xm - (pm-1) - 1)/sm,  1 + (xn - (pn-1) - 1)/sn\n",
    "    ym, yn = np.int(np.ceil(ym)), np.int(np.ceil(yn))\n",
    "    y = np.zeros((batch_size, ym, yn, num_channels))\n",
    "\n",
    "    for iy, ix in enumerate(range(0, xm-pm+1, sm)):\n",
    "        for jy, jx in enumerate(range(0, xn-pn+1, sn)):\n",
    "            chunk = input_batch[:, ix:ix+pm, jx:jx+pn, :]\n",
    "            y[:, iy, jy, :] = pool_fn(chunk, axis=(1,2))\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-timing",
   "metadata": {},
   "source": [
    "This looks a lot like the convolution functions implemented in the last post.  It extracts a chunk from the 4D array based on the pooling specification, and then executed `pool_fn` on each channel and for every batch. The lines\n",
    "```python\n",
    "y[:, iy, jy, :] = pool_fn(chunk, axis=(1,2))       \n",
    "```\n",
    "\n",
    "deserves a little explanation.  Although I didn't explictly mention it earlier, `pool_fn` is a vectorized function that's able to delegate it's work to some optimized low-level code.  If we didn't have vectorized functions, we'd have to use nested loops which we already know are very slow in Python.  The `axis=(1,2)` is saying that we want to perform the `pool_fn` only with respect to the height and width of an image for each batch and each channel.  For pooling, we don't care about the relative values between images in a batch, nor between different channels.  \n",
    "\n",
    "Here's a snippet of code that does what the code above does: only very slowly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "recreational-world",
   "metadata": {},
   "outputs": [],
   "source": [
    " def slow_max_pool(chunk):\n",
    "    num_items, height, width, num_channels = chunk.shape\n",
    "    result = np.zeros((num_items, num_channels))\n",
    "    for item in range(num_items):\n",
    "        for chan in range(num_channels):\n",
    "            max_val = -np.infty\n",
    "            for h in range(height):\n",
    "                for w in range(width):\n",
    "                    max_val = max(chunk[item, h, w, chan], max_val)\n",
    "            result[item, chan] = max_val\n",
    "    return result\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-laser",
   "metadata": {},
   "source": [
    "Just to make sure, let's compare them.  We'll define a random chunk, check that the vectorized and non-vectorized chunk-pooling give the same answer, and see how long each one takes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "helpful-variance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 µs ± 13.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "18.5 ms ± 486 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "chunk = np.random.randn(32, 28, 28, 3)\n",
    "result_vectorized = np.max(chunk, axis=(1,2))\n",
    "result_non_vectorized = slow_max_pool(chunk)\n",
    "\n",
    "assert np.all(np.isclose(result_non_vectorized, result_vectorized, atol=1e-6))\n",
    "\n",
    "%timeit -n 100 np.max(chunk, axis=(1,2))\n",
    "%timeit -n 100 slow_max_pool(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-palestinian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "athletic-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "jitted_filter_images_v2 = numba.jit(filter_images_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-philosophy",
   "metadata": {},
   "source": [
    "## Compare to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "physical-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keras = tf.keras.layers.MaxPool2D( \n",
    "    pool_size=(4, 4), \n",
    "    strides=(2,2),\n",
    "    padding='valid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "utility-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = np.random.randn(32,28,28,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "sixth-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch_keras = layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "thermal-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch_numpy = downsample_images(\n",
    "    input_batch, \n",
    "    pool_size=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    "    pool_fn = np.max\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-sunglasses",
   "metadata": {},
   "source": [
    "To check that the Keras output and numpy outputs are approximately equal, I make sure that the absolute error is below a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fifth-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(output_batch_keras,output_batch_numpy, atol=1e-16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-presence",
   "metadata": {},
   "source": [
    "Although the outputs are about the same, the Keras version runs much faster, as the following benchmarks show.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "structured-representative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.97 ms ± 216 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "downsample_images(\n",
    "    input_batch, \n",
    "    pool_size=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "included-needle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666 µs ± 52.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-script",
   "metadata": {},
   "source": [
    "### Pooling Layer in JAX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "comprehensive-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from typing import Tuple, List, Callable\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "suspected-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D: \n",
    "    pool_shape: Tuple[int,int]\n",
    "    strides: Tuple[int,int]\n",
    "    padding: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-administration",
   "metadata": {},
   "source": [
    "#### Constructor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "dominican-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __init__(\n",
    "    self: MaxPool2D, \n",
    "    pool_shape=(2,2), \n",
    "    strides=(1,1), \n",
    "    padding='valid'):\n",
    "    \n",
    "    self.pool_shape = pool_shape\n",
    "    self.strides = strides \n",
    "    self.padding = padding\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-haiti",
   "metadata": {},
   "source": [
    "#### `__call__` Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "passive-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __call__(self: MaxPool2D, batch: jnp.ndarray):\n",
    "    \n",
    "    pool_shape = (1, ) + self.pool_shape + (1, )\n",
    "    strides = (1, ) + self.strides + (1, ) \n",
    "    outputs = jax.lax.reduce_window(\n",
    "        batch,\n",
    "        -jnp.inf,\n",
    "        jax.lax.max,\n",
    "        window_dimensions=pool_shape,\n",
    "        window_strides=strides,\n",
    "        padding=self.padding\n",
    "    )\n",
    "\n",
    "    return outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-london",
   "metadata": {},
   "source": [
    "#### Adding to pytree Registry\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "varying-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def tree_flatten(self: MaxPool2D) -> Tuple[List[jnp.ndarray], dict]:\n",
    "    params = (None,)\n",
    "    metadata = {k: v for k, v in self.__dict__.items()}\n",
    "    return params, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "tutorial-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(cls_method=True)\n",
    "def tree_unflatten(cls: MaxPool2D, metadata: dict, params:List[jnp.ndarray]):\n",
    "    # This assumes that each key-value pair in the metadata dict corresponds to a constructor argument.\n",
    "    layer = cls(**metadata)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "chubby-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = jax.tree_util.register_pytree_node_class(MaxPool2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-cooper",
   "metadata": {},
   "source": [
    "## Compare JAX and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "coated-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_jax = MaxPool2D(\n",
    "    pool_shape=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    "    padding=layer_keras.padding\n",
    ")\n",
    "\n",
    "output_batch_jax = layer_jax(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-entrepreneur",
   "metadata": {},
   "source": [
    "Because the following assertion passes, we can be reassured that both layers are calculating the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "endangered-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.max(np.abs(output_batch_keras - output_batch_jax)) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-discipline",
   "metadata": {},
   "source": [
    "What about the calculation time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "center-negative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669 µs ± 40 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "undefined-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 µs ± 21.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "layer_jax(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-ratio",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9eb3d55570fa83a5d0e75ab0fc9e29d7692aa2022c5c86ae3b4c36003072d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
