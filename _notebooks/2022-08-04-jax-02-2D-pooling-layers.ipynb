{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conceptual-month",
   "metadata": {},
   "source": [
    "# Two Dimensional Pooling Layers\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: [jax, pooling]\n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-builder",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this post, I'll be implementing a 2D max-pooling layer from scratch and in JAX.  As before, we'll compare each version to Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-cruise",
   "metadata": {},
   "source": [
    "## Purpose of Pooling Layers\n",
    "\n",
    "Pooling layers reduce the number of parameters in convolutional neural networks by downsampling the feature maps generated by the convolutional layers.  Under the hood, they are actually very similar to convolutional layers.  Both layers work by stepping through an input image based on a stride, extracting a chunk of a specified size,  and compressing 3D chunk with some sort of computation.  The main difference between the two layers is the computation.  Recall from the last post that convolutional layers compresses a chunk to a single number by multiplying it's elements with a set of filter coefficients, summing the products, and adding a bias term.  There aren't any filters nor bias terms in pooling layers.  They use simple functions (e.g. `max`, `mean`, etc) that don't depend on any learnable parameters to compress each chunk.  \n",
    "\n",
    "Unlike convolutional layers, pooling layer retain the number of input channels in the input image.  So you can think of these *pooling functions* as being applied to each channel separately and merged back together.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-integral",
   "metadata": {},
   "source": [
    "## Implementation from First Principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-providence",
   "metadata": {},
   "source": [
    "Here's an implementation of a pooling layer.  You can configure how each chunk gets downsampled by choosing different pooling function, `pool_fn`. Because `pool_fn` is set to `np.max` in the argument list, max-pooling is executed by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "persistent-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_images(input_batch, pool_size, strides, pool_fn=np.max):\n",
    "    batch_size, xm, xn, num_channels  = input_batch.shape \n",
    "    \n",
    "    pm, pn = pool_size \n",
    "    sm, sn = strides\n",
    "    \n",
    "    #ym, yn = 1 + ((xm - pm)//sm), 1 + ((xn - pn)//sn) \n",
    "    ym, yn = 1 + (xm - (pm-1) - 1)/sm,  1 + (xn - (pn-1) - 1)/sn\n",
    "    ym, yn = np.int(np.ceil(ym)), np.int(np.ceil(yn))\n",
    "    y = np.zeros((batch_size, ym, yn, num_channels))\n",
    "\n",
    "    for iy, ix in enumerate(range(0, xm-pm+1, sm)):\n",
    "        for jy, jx in enumerate(range(0, xn-pn+1, sn)):\n",
    "            y[:, iy, jy, :] = pool_fn(\n",
    "                input_batch[:, ix:ix+pm, jx:jx+pn, :],\n",
    "                axis=(1,2)\n",
    "            )         \n",
    "    return y    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-doctor",
   "metadata": {},
   "source": [
    "This is a lot like the convolution functions implemented in the last post.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-granny",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-right",
   "metadata": {},
   "source": [
    "## Compare to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cognitive-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keras = tf.keras.layers.MaxPool2D( \n",
    "    pool_size=(4, 4), \n",
    "    strides=(2,2),\n",
    "    padding='valid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "environmental-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = np.random.randn(32,28,28,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "hollow-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch_keras = layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "pressing-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch_numpy = downsample_images(\n",
    "    input_batch, \n",
    "    pool_size=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    "    pool_fn = np.max\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-scottish",
   "metadata": {},
   "source": [
    "To check that the Keras output and numpy outputs are approximately equal, I make sure that the absolute error is below a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "parental-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(output_batch_keras,output_batch_numpy, atol=1e-16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-address",
   "metadata": {},
   "source": [
    "Although the outputs are about the same, the Keras version runs much faster, as the following benchmarks show.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "remarkable-acquisition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.61 ms ± 47.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "downsample_images(\n",
    "    input_batch, \n",
    "    pool_size=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "finite-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666 µs ± 52.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-colombia",
   "metadata": {},
   "source": [
    "### Pooling Layer in JAX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "manufactured-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from typing import Tuple, List, Callable\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "lightweight-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D: \n",
    "    pool_shape: Tuple[int,int]\n",
    "    strides: Tuple[int,int]\n",
    "    padding: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-movie",
   "metadata": {},
   "source": [
    "#### Constructor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "amateur-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __init__(\n",
    "    self: MaxPool2D, \n",
    "    pool_shape=(2,2), \n",
    "    strides=(1,1), \n",
    "    padding='valid'):\n",
    "    \n",
    "    self.pool_shape = pool_shape\n",
    "    self.strides = strides \n",
    "    self.padding = padding\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-phrase",
   "metadata": {},
   "source": [
    "#### `__call__` Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "elder-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __call__(self: MaxPool2D, batch: jnp.ndarray):\n",
    "    \n",
    "    pool_shape = (1, ) + self.pool_shape + (1, )\n",
    "    strides = (1, ) + self.strides + (1, ) \n",
    "    outputs = jax.lax.reduce_window(\n",
    "        batch,\n",
    "        -jnp.inf,\n",
    "        jax.lax.max,\n",
    "        window_dimensions=pool_shape,\n",
    "        window_strides=strides,\n",
    "        padding=self.padding\n",
    "    )\n",
    "\n",
    "    return outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-fighter",
   "metadata": {},
   "source": [
    "#### Adding to pytree Registry\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ruled-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def tree_flatten(self: MaxPool2D) -> Tuple[List[jnp.ndarray], dict]:\n",
    "    params = (None,)\n",
    "    metadata = {k: v for k, v in self.__dict__.items()}\n",
    "    return params, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "proud-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(cls_method=True)\n",
    "def tree_unflatten(cls: MaxPool2D, metadata: dict, params:List[jnp.ndarray]):\n",
    "    # This assumes that each key-value pair in the metadata dict corresponds to a constructor argument.\n",
    "    layer = cls(**metadata)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "satellite-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = jax.tree_util.register_pytree_node_class(MaxPool2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-venture",
   "metadata": {},
   "source": [
    "## Compare JAX and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "agricultural-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_jax = MaxPool2D(\n",
    "    pool_shape=layer_keras.pool_size,\n",
    "    strides=layer_keras.strides,\n",
    "    padding=layer_keras.padding\n",
    ")\n",
    "\n",
    "output_batch_jax = layer_jax(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-magnitude",
   "metadata": {},
   "source": [
    "Because the following assertion passes, we can be reassured that both layers are calculating the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bigger-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.max(np.abs(output_batch_keras - output_batch_jax)) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-aruba",
   "metadata": {},
   "source": [
    "What about the calculation time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "nasty-outline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669 µs ± 40 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "layer_keras(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "printable-mandate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 µs ± 21.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "layer_jax(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-update",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9eb3d55570fa83a5d0e75ab0fc9e29d7692aa2022c5c86ae3b4c36003072d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
