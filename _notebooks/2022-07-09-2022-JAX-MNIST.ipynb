{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "direct-series",
   "metadata": {},
   "source": [
    "# Fashion MNIST using Linear Layers with JAX\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]\n",
    "- image: images/chart-preview.png\n",
    "- hide: true\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "burning-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 15:40:07.488699: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/bin:/usr/local/lib:\n"
     ]
    }
   ],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import Tuple, List, Any, Dict, Callable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c7223",
   "metadata": {},
   "source": [
    "## PyTorch / fast.ai like Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7328e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "    def __len__(self):\n",
    "        return jnp.shape(self.X)[0]\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i,:], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb809fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, dataset: Dataset, batchsize=32, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.shuffle = shuffle\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.dataset), self.batchsize): \n",
    "            yield self.dataset[i:i+self.batchsize]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51fe6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477c4a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras.datasets.fashion_mnist.load_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\"Loads the Fashion-MNIST dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories,\u001b[0m\n",
      "\u001b[0;34m  along with a test set of 10,000 images. This dataset can be used as\u001b[0m\n",
      "\u001b[0;34m  a drop-in replacement for MNIST.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  The classes are:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  | Label | Description |\u001b[0m\n",
      "\u001b[0;34m  |:-----:|-------------|\u001b[0m\n",
      "\u001b[0;34m  |   0   | T-shirt/top |\u001b[0m\n",
      "\u001b[0;34m  |   1   | Trouser     |\u001b[0m\n",
      "\u001b[0;34m  |   2   | Pullover    |\u001b[0m\n",
      "\u001b[0;34m  |   3   | Dress       |\u001b[0m\n",
      "\u001b[0;34m  |   4   | Coat        |\u001b[0m\n",
      "\u001b[0;34m  |   5   | Sandal      |\u001b[0m\n",
      "\u001b[0;34m  |   6   | Shirt       |\u001b[0m\n",
      "\u001b[0;34m  |   7   | Sneaker     |\u001b[0m\n",
      "\u001b[0;34m  |   8   | Bag         |\u001b[0m\n",
      "\u001b[0;34m  |   9   | Ankle boot  |\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Returns:\u001b[0m\n",
      "\u001b[0;34m    Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **x_train**: uint8 NumPy array of grayscale image data with shapes\u001b[0m\n",
      "\u001b[0;34m    `(60000, 28, 28)`, containing the training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **y_train**: uint8 NumPy array of labels (integers in range 0-9)\u001b[0m\n",
      "\u001b[0;34m    with shape `(60000,)` for the training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **x_test**: uint8 NumPy array of grayscale image data with shapes\u001b[0m\n",
      "\u001b[0;34m    (10000, 28, 28), containing the test data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **y_test**: uint8 NumPy array of labels (integers in range 0-9)\u001b[0m\n",
      "\u001b[0;34m    with shape `(10000,)` for the test data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  ```python\u001b[0m\n",
      "\u001b[0;34m  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\u001b[0m\n",
      "\u001b[0;34m  assert x_train.shape == (60000, 28, 28)\u001b[0m\n",
      "\u001b[0;34m  assert x_test.shape == (10000, 28, 28)\u001b[0m\n",
      "\u001b[0;34m  assert y_train.shape == (60000,)\u001b[0m\n",
      "\u001b[0;34m  assert y_test.shape == (10000,)\u001b[0m\n",
      "\u001b[0;34m  ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  License:\u001b[0m\n",
      "\u001b[0;34m    The copyright for Fashion-MNIST is held by Zalando SE.\u001b[0m\n",
      "\u001b[0;34m    Fashion-MNIST is licensed under the [MIT license](\u001b[0m\n",
      "\u001b[0;34m    https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fashion-mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;34m'train-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;34m't10k-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't10k-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlbpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimgpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mimgpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlbpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimgpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mimgpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.8/site-packages/keras/datasets/fashion_mnist.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist.load_data??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c49dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc06bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Dataloader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "813f493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n"
     ]
    }
   ],
   "source": [
    "for X, y in dataloader:\n",
    "    print(X.shape, y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-language",
   "metadata": {},
   "source": [
    "## Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377559ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module: pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8b9d2",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0c53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    w: jnp.ndarray \n",
    "    b: jnp.ndarray\n",
    "    ni: int \n",
    "    no: int \n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, seed=1234):\n",
    "        self.ni = num_inputs \n",
    "        self.no = num_outputs \n",
    "        key = jax.random.PRNGKey(seed)\n",
    "        self.w = jax.random.normal(key, (num_inputs, num_outputs)) * jnp.sqrt(2.0 / num_inputs)\n",
    "        self.b = jnp.zeros(num_outputs)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return jnp.dot(x, self.w) + self.b\n",
    "        \n",
    "    def params(self):\n",
    "        return {'b': self.b, 'w': self.w}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8143a664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.37713784]\n",
      " [ 0.5444933 ]\n",
      " [ 0.9541705 ]\n",
      " [ 0.3122406 ]\n",
      " [-0.03162232]]\n"
     ]
    }
   ],
   "source": [
    "l = Linear(2, 1)\n",
    "x = np.random.randn(5,2)\n",
    "y = l(x)\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af8158d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(model, X, y):\n",
    "    preds = jax.vmap(model)(X)\n",
    "    return jnp.mean((preds - y)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c84e6e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.167813\n",
      "1.0486954\n"
     ]
    }
   ],
   "source": [
    "print(mse(l, x, 2.0))\n",
    "print(mse(l, np.random.randn(10, 2), np.random.randn(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2280d8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument '<__main__.Linear object at 0x7fd2a0592f70>' of type <class '__main__.Linear'> is not a valid JAX type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_147578/2465860446.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmse_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmse_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_check_arg\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m   2972\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2973\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_valid_jaxtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2974\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Argument '{arg}' of type {type(arg)} is not a valid JAX type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2976\u001b[0m \u001b[0;31m# TODO(mattjj,necula): this duplicates code in core.valid_jaxtype, but one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument '<__main__.Linear object at 0x7fd2a0592f70>' of type <class '__main__.Linear'> is not a valid JAX type."
     ]
    }
   ],
   "source": [
    "mse_grad = jax.grad(mse)\n",
    "mse_grad(l, x, 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fce192",
   "metadata": {},
   "source": [
    "To get this to work, the `Linear` class must be registered as a pytree.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b38d3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.tree_util.register_pytree_node_class\n",
    "class Linear(Module):\n",
    "    w: jnp.ndarray \n",
    "    b: jnp.ndarray\n",
    "    ni: int \n",
    "    no: int \n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, build=True, seed=1234):\n",
    "        self.ni = num_inputs \n",
    "        self.no = num_outputs \n",
    "        # want to add seed as internal object\n",
    "        if build:\n",
    "            key = jax.random.PRNGKey(seed)\n",
    "            self.w = jax.random.normal(key, (num_inputs, num_outputs)) * jnp.sqrt(2.0 / num_inputs)\n",
    "            self.b = jnp.zeros(num_outputs)\n",
    "    \n",
    "    def merge(self, params):\n",
    "        self.w, self.b = params\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Linear(num_inputs={self.ni}, num_outputs={self.no})'\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return jnp.dot(x, self.w) + self.b\n",
    "        \n",
    "    def params(self):\n",
    "        return {'b': self.b, 'w': self.w}\n",
    "\n",
    "    def tree_flatten(self):\n",
    "        return [self.w, self.b], [self.ni, self.no]\n",
    "\n",
    "    @classmethod\n",
    "    def tree_unflatten(cls, aux_data, children):\n",
    "        layer = cls(*aux_data, build=False)\n",
    "        layer.merge(params=children)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e0498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = Linear(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44dc2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, extra_stuff = lin.tree_flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1be4bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin2 = Linear.tree_unflatten(extra_stuff, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4788c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43957582]\n",
      " [-0.26563603]]\n",
      "[[ 0.43957582]\n",
      " [-0.26563603]]\n"
     ]
    }
   ],
   "source": [
    "print(lin.w)\n",
    "print(lin2.w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4609b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@jax.value_and_grad\n",
    "def mse(model, X, y):\n",
    "    preds = jax.vmap(model)(X)\n",
    "    return jnp.mean((preds - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a924cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2169735 Linear(num_inputs=2, num_outputs=1)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randn(10, 2)\n",
    "y = np.random.randn(10)\n",
    "\n",
    "loss, g_loss = mse(lin, X, y)\n",
    "print(loss, g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edcb6098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ni': 2,\n",
       " 'no': 1,\n",
       " 'w': DeviceArray([[ 1.5454377 ],\n",
       "              [-0.11858664]], dtype=float32),\n",
       " 'b': DeviceArray([-0.7558269], dtype=float32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cbf1732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([DeviceArray([[ 1.5454377 ],\n",
       "               [-0.11858664]], dtype=float32),\n",
       "  DeviceArray([-0.7558269], dtype=float32)],\n",
       " PyTreeDef(CustomNode(<class '__main__.Linear'>[[2, 1]], [*, *])))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_util.tree_flatten(g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acecd62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()['Linear'].__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dadd9d",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e036946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x: jnp.ndarray): \n",
    "    shape = jnp.shape(x)\n",
    "    new_shape = -1 if len(shape) == 1 else (shape[0], -1) \n",
    "    return jnp.reshape(x, new_shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c5c167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: jnp.ndarray): \n",
    "    return jnp.clip(x, a_min=0)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f3a1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10,10)\n",
    "assert jnp.all(jnp.isclose(relu(x), jax.nn.relu(x))), 'test failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e231d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: jnp.ndarray):\n",
    "    ex = jnp.exp(x)\n",
    "    return ex / jnp.sum(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "352fe9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10)\n",
    "assert jnp.all(jnp.isclose(softmax(x), jax.nn.softmax(x))), 'test failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81d624ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "_registry = {\n",
    "    flatten.__name__: flatten,\n",
    "    softmax.__name__: softmax,\n",
    "    relu.__name__: relu\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb3daa",
   "metadata": {},
   "source": [
    "### Sequential Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8490f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.tree_util.register_pytree_node_class\n",
    "class Sequential(Module):\n",
    "    layers: List\n",
    "    def __init__(self, *layers):\n",
    "        self.layers = layers\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    def tree_flatten(self):\n",
    "        aux_data, children = [], []\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Module):\n",
    "                params, extra_stuff = layer.tree_flatten()\n",
    "                aux_data.append([layer.__class__.__name__] + extra_stuff)\n",
    "                children.append(params) \n",
    "            elif callable(layer):\n",
    "                # a layer function that doesn't have any paramerers ...\n",
    "                aux_data.append(layer.__name__)\n",
    "                children.append(None)    \n",
    "        return children, aux_data\n",
    "    @classmethod\n",
    "    def tree_unflatten(cls, aux_data, children):\n",
    "        layers = []\n",
    "        # Want a more generic way to unflatten\n",
    "        for params, spec in zip(children, aux_data):\n",
    "            if isinstance(spec, list):\n",
    "                layer_name, *args = spec\n",
    "                if layer_name == 'Linear':\n",
    "                    layers.append(Linear.tree_unflatten(args, params))   \n",
    "            elif isinstance(spec, str) and spec in _registry:\n",
    "                layers.append(_registry[spec])\n",
    "        return Sequential(*layers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e871ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flatten', ['Linear', 784, 128], 'relu', ['Linear', 128, 10], 'softmax']\n",
      "[None, [DeviceArray([[-0.00503162, -0.11710759,  0.05479915, ..., -0.07662067,\n",
      "              -0.03762808,  0.037621  ],\n",
      "             [-0.02311066,  0.00427538,  0.06703123, ...,  0.05820996,\n",
      "              -0.03371886, -0.0653995 ],\n",
      "             [-0.03936624,  0.08184296, -0.00103856, ..., -0.02543773,\n",
      "               0.00404367,  0.10533019],\n",
      "             ...,\n",
      "             [-0.05674443,  0.01220774, -0.04277196, ...,  0.00793091,\n",
      "              -0.03246848,  0.05214054],\n",
      "             [-0.10229313, -0.04473471, -0.05902693, ..., -0.026743  ,\n",
      "               0.01399903, -0.02305236],\n",
      "             [ 0.02624378, -0.040582  ,  0.04346804, ..., -0.0069246 ,\n",
      "               0.04329436,  0.07048796]], dtype=float32), DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)], None, [DeviceArray([[-0.01355871,  0.03681665, -0.03254633, ...,  0.08429167,\n",
      "              -0.23054102, -0.17765395],\n",
      "             [ 0.10870937, -0.09912576, -0.15005781, ..., -0.02846045,\n",
      "              -0.17202236,  0.05921352],\n",
      "             [-0.04855632, -0.1232295 , -0.08703142, ..., -0.01804219,\n",
      "              -0.05857573, -0.05169024],\n",
      "             ...,\n",
      "             [-0.04422821,  0.02535993, -0.09997344, ..., -0.15334168,\n",
      "              -0.07498863, -0.08412767],\n",
      "             [-0.10158557,  0.035592  , -0.01597822, ..., -0.17800951,\n",
      "               0.01484985, -0.03984371],\n",
      "             [ 0.10285417, -0.07429263, -0.03157486, ..., -0.09978219,\n",
      "               0.09220438, -0.01050255]], dtype=float32), DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)], None]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fashion_mnist_mlp():\n",
    "    model = Sequential(\n",
    "        flatten,\n",
    "        Linear(784, 128),\n",
    "        relu,\n",
    "        Linear(128, 10),\n",
    "        softmax   \n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = fashion_mnist_mlp()\n",
    "params, extra_stuff = model.tree_flatten()\n",
    "print(extra_stuff)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-spirit",
   "metadata": {},
   "source": [
    "## Cross-entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83a6e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.value_and_grad\n",
    "def cross_entropy(model, X, y, num_cats=10):\n",
    "    y_one_hot = jax.nn.one_hot(y, num_cats)\n",
    "    log_softmax = jnp.log(jax.vmap(model)(X))\n",
    "    return -jnp.mean(log_softmax * y_one_hot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf096acd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Incompatible shapes for dot: got (28, 28) and (784, 128).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_147578/2426296439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_147578/140557507.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(model, X, y, num_cats)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlog_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_147578/1928037884.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_147578/3007004617.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 23 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   2724\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mb_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(lhs, rhs, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m    654\u001b[0m                        preferred_element_type=preferred_element_type)\n\u001b[1;32m    655\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m     raise TypeError(\"Incompatible shapes for dot: got {} and {}.\".format(\n\u001b[0m\u001b[1;32m    657\u001b[0m         lhs.shape, rhs.shape))\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Incompatible shapes for dot: got (28, 28) and (784, 128)."
     ]
    }
   ],
   "source": [
    "\n",
    "value, grads = cross_entropy(model, np.random.randn(5, 28, 28), [1,0,1,1,0])\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae5c4f72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_147578/3807978763.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mupdated_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grads' is not defined"
     ]
    }
   ],
   "source": [
    "updated_model = jax.tree_util.tree_map(lambda p, g: p - 1e-3*g, model, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2e382c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'updated_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_147578/2008119821.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'updated_model' is not defined"
     ]
    }
   ],
   "source": [
    "assert jnp.all(jnp.isclose(updated_model.layers[1].w, model.layers[1].w - 1e-3*grads.layers[1].w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be35ef",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db693299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer: pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c353f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    def __init__(self, model, lr=1e-3):\n",
    "        self.lr = lr \n",
    "    def step(self, model, grads):\n",
    "        return jax.tree_map(lambda p, g: p - self.lr*g, model, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67d1a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "    def __init__(self, model, lr=1e-3, v_decay=0.9, s_decay=0.999, eps=1e-7):\n",
    "        self.lr, self.v_decay, self.s_decay, self.eps = lr, v_decay, s_decay, eps\n",
    "        self.v = jax.tree_map(lambda x: jnp.zeros_like(x), model) \n",
    "        self.s = jax.tree_map(lambda x: jnp.zeros_like(x), model)\n",
    "        self.k = 0 \n",
    "    def step(self, model, grads):\n",
    "        lr, v_decay, s_decay, eps = self.lr, self.v_decay, self.s_decay, self.eps\n",
    "        k = self.k = self.k+1\n",
    "        self.v = jax.tree_map(lambda v, g: v_decay*v +(1-v_decay)*g, self.v, grads)\n",
    "        self.s = jax.tree_map(lambda s, g: s_decay*s +(1-s_decay)*g*g, self.s, grads)\n",
    "        v_hat = jax.tree_map(lambda v: v / (1-v_decay**k), self.v)\n",
    "        s_hat = jax.tree_map(lambda s: s / (1-s_decay**k), self.s)\n",
    "        new_model = jax.tree_map(lambda params, v_hat, s_hat: params - (lr*v_hat)/(jnp.sqrt(s_hat) + eps), model, v_hat, s_hat)\n",
    "        return new_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-knock",
   "metadata": {},
   "source": [
    "## Training Loop  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4c652",
   "metadata": {},
   "source": [
    "## API Improvements\n",
    "\n",
    "I can't claim the credit for the API implemented in this section; it's **heavily** inspired by the excellent fastai library.  I'm not lifting code from the fastai repository, but I'm definitely using some of the . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "deb79c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict \n",
    "\n",
    "def train(num_epochs, train_datasource, valid_datasource, optimizer, loss_fn, grad_fn, model):\n",
    "    history = {'loss':[], 'accuracy':[]}\n",
    "    \n",
    "    if valid_datasource is not None:\n",
    "        history = {**history, 'valid_loss': [], 'valid_accuracy': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # TRAINING PHASE\n",
    "        loss_accum, accuracy_accum, sample_cnt = 0, 0, 0\n",
    "        \n",
    "        for X_train, y_train in train_datasource:\n",
    "\n",
    "            # training loss and gradients for this particular batch\n",
    "            probs = model(X_train)#jax.vmap(model)(X_train)\n",
    "            loss = loss_fn(probs, y_train)\n",
    "            \n",
    "            grads = grad_fn(model, X_train, y_train)\n",
    "            model = optimizer.step(model, grads)\n",
    "            \n",
    "            #loss, grad = loss_fn(net, X_train, y_train)\n",
    "\n",
    "            # update the model using gradient descent\n",
    "            #net = optimizer.step(net, grad)\n",
    "                \n",
    "            # update for metrics\n",
    "            loss_accum += loss\n",
    "            sample_cnt += len(y_train)\n",
    "            accuracy_accum += jnp.sum(jnp.argmax(probs, axis=-1) == y_train)\n",
    "            #accuracy_accum += jnp.sum(jnp.argmax(jax.vmap(net)(X_train), axis=-1) == y_train)\n",
    "\n",
    "\n",
    "        epoch_train_loss = loss_accum / sample_cnt \n",
    "        epoch_train_accuracy = accuracy_accum / sample_cnt\n",
    "\n",
    "        history['loss'].append(epoch_train_loss)\n",
    "        history['accuracy'].append(epoch_train_accuracy)      \n",
    "\n",
    "        # VALIDATION PHASE\n",
    "        if valid_datasource is not None:\n",
    "            loss_accum, accuracy_accum, sample_cnt = 0, 0, 0 \n",
    "\n",
    "            # Run validation step ...\n",
    "            for X_valid, y_valid in valid_datasource:\n",
    "                probs = model(X_valid)\n",
    "                loss = loss_fn(probs, y_valid)\n",
    "                \n",
    "                accuracy_accum += jnp.sum(jnp.argmax(probs, axis=-1) == y_valid)\n",
    "                #loss, _ = loss_fn(net, X_valid, y_valid)\n",
    "\n",
    "                #y_pred = predict(X_train)\n",
    "                \n",
    "                #valid_loss = loss_fn(predict(X_valid), y_valid)\n",
    "                loss_accum += loss\n",
    "                sample_cnt += len(y_valid)\n",
    "                #accuracy_accum += jnp.sum(jnp.argmax(jax.vmap(net)(X_valid), axis=-1) == y_valid)\n",
    "\n",
    "            epoch_valid_loss = loss_accum / sample_cnt \n",
    "            epoch_valid_accuracy = accuracy_accum / sample_cnt\n",
    "\n",
    "            history['loss'].append(epoch_valid_loss)\n",
    "            history['accuracy'].append(epoch_valid_accuracy)\n",
    "  \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'train_loss: {epoch_train_loss:.6f} , train_accuracy: {100*epoch_train_accuracy:.2f}', end='')\n",
    "        if valid_datasource:\n",
    "            print(f' , ', end='')\n",
    "        print(f'valid_loss: {epoch_valid_loss:.6f} , valid_accuracy: {100*epoch_valid_accuracy:.2f}')\n",
    "    return history\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "862345d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fashion_mnist_loss(probs, y_true):\n",
    "    y_one_hot = jax.nn.one_hot(y_true, 10)\n",
    "    return -jnp.mean(jnp.log(probs) * y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91ee7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jax.value_and_grad\n",
    "#def fashion_mnist_loss(model, X, y):\n",
    "#    y_one_hot = jax.nn.one_hot(y, 10)\n",
    "#    log_softmax = jnp.log(jax.vmap(model)(X))\n",
    "#    return -jnp.mean(log_softmax * y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "883ecd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "train_loss: 0.007568 , train_accuracy: 80.38 , valid_loss: 0.007337 , valid_accuracy: 84.12\n",
      "Epoch 2/5\n",
      "train_loss: 0.007250 , train_accuracy: 85.44 , valid_loss: 0.007235 , valid_accuracy: 85.59\n",
      "Epoch 3/5\n",
      "train_loss: 0.007160 , train_accuracy: 86.83 , valid_loss: 0.007178 , valid_accuracy: 86.43\n",
      "Epoch 4/5\n",
      "train_loss: 0.007110 , train_accuracy: 87.64 , valid_loss: 0.007146 , valid_accuracy: 87.08\n",
      "Epoch 5/5\n",
      "train_loss: 0.007075 , train_accuracy: 88.32 , valid_loss: 0.007117 , valid_accuracy: 87.49\n"
     ]
    }
   ],
   "source": [
    "X_train_, y_train_ = X_train[:40_000,:,:], y_train[:40_000]\n",
    "X_valid, y_valid = X_train[40_000:,:,:], y_train[40_000:]\n",
    "\n",
    "train_dataset = Dataset(X_train_, y_train_)\n",
    "valid_dataset = Dataset(X_valid, y_valid)\n",
    "\n",
    "train_datasource = Dataloader(train_dataset, batchsize=64)\n",
    "valid_datasource = Dataloader(valid_dataset, batchsize=64)\n",
    "model = fashion_mnist_mlp()\n",
    "\n",
    "#@jax.grad\n",
    "#def grad_fn(model, X, y):\n",
    "#    y_one_hot = jax.nn.one_hot(y, 10)\n",
    "#    log_softmax = jnp.log(model(X))\n",
    "#    return -jnp.mean(log_softmax * y_one_hot)\n",
    "\n",
    "grad_fn = jax.grad(lambda model, X, y: fashion_mnist_loss(model(X), y))\n",
    "\n",
    "history = train(\n",
    "    num_epochs=5, \n",
    "    train_datasource=train_datasource, \n",
    "    valid_datasource=valid_datasource, \n",
    "    optimizer=Adam(model, lr=1e-3), \n",
    "    loss_fn=fashion_mnist_loss, \n",
    "    model=model,\n",
    "    grad_fn=grad_fn\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-finder",
   "metadata": {},
   "source": [
    "## Performance Curve\n",
    "\n",
    "Let's see the trend in the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-hudson",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ae1bd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\"Just your regular densely-connected NN layer.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  `Dense` implements the operation:\u001b[0m\n",
      "\u001b[0;34m  `output = activation(dot(input, kernel) + bias)`\u001b[0m\n",
      "\u001b[0;34m  where `activation` is the element-wise activation function\u001b[0m\n",
      "\u001b[0;34m  passed as the `activation` argument, `kernel` is a weights matrix\u001b[0m\n",
      "\u001b[0;34m  created by the layer, and `bias` is a bias vector created by the layer\u001b[0m\n",
      "\u001b[0;34m  (only applicable if `use_bias` is `True`). These are all attributes of\u001b[0m\n",
      "\u001b[0;34m  `Dense`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Note: If the input to the layer has a rank greater than 2, then `Dense`\u001b[0m\n",
      "\u001b[0;34m  computes the dot product between the `inputs` and the `kernel` along the\u001b[0m\n",
      "\u001b[0;34m  last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\u001b[0m\n",
      "\u001b[0;34m  For example, if input has dimensions `(batch_size, d0, d1)`,\u001b[0m\n",
      "\u001b[0;34m  then we create a `kernel` with shape `(d1, units)`, and the `kernel` operates\u001b[0m\n",
      "\u001b[0;34m  along axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`\u001b[0m\n",
      "\u001b[0;34m  (there are `batch_size * d0` such sub-tensors).\u001b[0m\n",
      "\u001b[0;34m  The output in this case will have shape `(batch_size, d0, units)`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Besides, layer attributes cannot be modified after the layer has been called\u001b[0m\n",
      "\u001b[0;34m  once (except the `trainable` attribute).\u001b[0m\n",
      "\u001b[0;34m  When a popular kwarg `input_shape` is passed, then keras will create\u001b[0m\n",
      "\u001b[0;34m  an input layer to insert before the current layer. This can be treated\u001b[0m\n",
      "\u001b[0;34m  equivalent to explicitly defining an `InputLayer`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  >>> # Create a `Sequential` model and add a Dense layer as the first layer.\u001b[0m\n",
      "\u001b[0;34m  >>> model = tf.keras.models.Sequential()\u001b[0m\n",
      "\u001b[0;34m  >>> model.add(tf.keras.Input(shape=(16,)))\u001b[0m\n",
      "\u001b[0;34m  >>> model.add(tf.keras.layers.Dense(32, activation='relu'))\u001b[0m\n",
      "\u001b[0;34m  >>> # Now the model will take as input arrays of shape (None, 16)\u001b[0m\n",
      "\u001b[0;34m  >>> # and output arrays of shape (None, 32).\u001b[0m\n",
      "\u001b[0;34m  >>> # Note that after the first layer, you don't need to specify\u001b[0m\n",
      "\u001b[0;34m  >>> # the size of the input anymore:\u001b[0m\n",
      "\u001b[0;34m  >>> model.add(tf.keras.layers.Dense(32))\u001b[0m\n",
      "\u001b[0;34m  >>> model.output_shape\u001b[0m\n",
      "\u001b[0;34m  (None, 32)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Args:\u001b[0m\n",
      "\u001b[0;34m    units: Positive integer, dimensionality of the output space.\u001b[0m\n",
      "\u001b[0;34m    activation: Activation function to use.\u001b[0m\n",
      "\u001b[0;34m      If you don't specify anything, no activation is applied\u001b[0m\n",
      "\u001b[0;34m      (ie. \"linear\" activation: `a(x) = x`).\u001b[0m\n",
      "\u001b[0;34m    use_bias: Boolean, whether the layer uses a bias vector.\u001b[0m\n",
      "\u001b[0;34m    kernel_initializer: Initializer for the `kernel` weights matrix.\u001b[0m\n",
      "\u001b[0;34m    bias_initializer: Initializer for the bias vector.\u001b[0m\n",
      "\u001b[0;34m    kernel_regularizer: Regularizer function applied to\u001b[0m\n",
      "\u001b[0;34m      the `kernel` weights matrix.\u001b[0m\n",
      "\u001b[0;34m    bias_regularizer: Regularizer function applied to the bias vector.\u001b[0m\n",
      "\u001b[0;34m    activity_regularizer: Regularizer function applied to\u001b[0m\n",
      "\u001b[0;34m      the output of the layer (its \"activation\").\u001b[0m\n",
      "\u001b[0;34m    kernel_constraint: Constraint function applied to\u001b[0m\n",
      "\u001b[0;34m      the `kernel` weights matrix.\u001b[0m\n",
      "\u001b[0;34m    bias_constraint: Constraint function applied to the bias vector.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Input shape:\u001b[0m\n",
      "\u001b[0;34m    N-D tensor with shape: `(batch_size, ..., input_dim)`.\u001b[0m\n",
      "\u001b[0;34m    The most common situation would be\u001b[0m\n",
      "\u001b[0;34m    a 2D input with shape `(batch_size, input_dim)`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Output shape:\u001b[0m\n",
      "\u001b[0;34m    N-D tensor with shape: `(batch_size, ..., units)`.\u001b[0m\n",
      "\u001b[0;34m    For instance, for a 2D input with shape `(batch_size, input_dim)`,\u001b[0m\n",
      "\u001b[0;34m    the output would have shape `(batch_size, units)`.\u001b[0m\n",
      "\u001b[0;34m  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Received an invalid value for `units`, expected '\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                       \u001b[0;34mf'a positive integer. Received: units={units}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A Dense layer can only be built with a floating-point '\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                      \u001b[0;34mf'dtype. Received: dtype={dtype}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlast_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mlast_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The last dimension of the inputs to a Dense layer '\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                       \u001b[0;34m'should be defined. Found None. '\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                       \u001b[0;34mf'Full input shape received: {input_shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRaggedTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# In case we encounter a RaggedTensor with a fixed last dimension (last\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# dimension not ragged), we can map the call method to the flat values.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mragged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_flat_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# We use embedding_lookup_sparse as a more efficient matmul operation for\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# large sparse input tensors. The op will result in a sparse gradient, as\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# opposed to sparse_ops.sparse_tensor_dense_matmul which results in dense\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# gradients. This can lead to sigfinicant speedups, see b/171762937.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# We need to fill empty rows, as the op assumes at least one id per row.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_empty_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# We need to do some munging of our input to use the embedding lookup as\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# a matrix multiply. We split our input matrix into separate ids and\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# weights tensors. The values of the ids tensor should be the column\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# indices of our input matrix and the values of the weights tensor\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# can continue to the actual matrix weights.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# The column arrangement of ids and weights\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# will be summed over and does not matter. See the documentation for\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# sparse_ops.sparse_tensor_dense_matmul a more detailed explanation\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# of the inputs to both ops.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdense_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombiner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank_at_least\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The last dimension of the input shape of a Dense layer '\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                       \u001b[0;34m'should be defined. Found None. '\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                       \u001b[0;34mf'Received: input_shape={input_shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'units'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'activation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'use_bias'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'kernel_initializer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'bias_initializer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'kernel_regularizer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'bias_regularizer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'activity_regularizer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'kernel_constraint'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'bias_constraint'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.8/site-packages/keras/layers/core/dense.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     Dense\n"
     ]
    }
   ],
   "source": [
    "tf.keras.layers.Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a71b05bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n",
      "\n",
      "Prints the values to a stream, or to sys.stdout by default.\n",
      "Optional keyword arguments:\n",
      "file:  a file-like object (stream); defaults to the current sys.stdout.\n",
      "sep:   string inserted between values, default a space.\n",
      "end:   string appended after the last value, default a newline.\n",
      "flush: whether to forcibly flush the stream.\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
     ]
    }
   ],
   "source": [
    "print??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "bb86319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fashion_mnist_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "070b0869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.randn(2,28,28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "367e77be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.36403014, -0.35703367,  0.45756755, ...,  0.53845649,\n",
       "        -0.44979458, -0.77233799],\n",
       "       [-0.98455966, -0.17481828,  1.16870836, ...,  0.91413078,\n",
       "         0.46064645, -1.13064741]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(np.random.randn(2,28,28), (2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "e2f44384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.shape(np.random.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae866c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9eb3d55570fa83a5d0e75ab0fc9e29d7692aa2022c5c86ae3b4c36003072d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
