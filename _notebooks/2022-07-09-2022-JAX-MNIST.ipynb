{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "direct-series",
   "metadata": {},
   "source": [
    "# Fashion MNIST using Linear Layers with JAX\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]\n",
    "- image: images/chart-preview.png\n",
    "- hide: true\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "burning-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 21:52:53.905857: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/bin:/usr/local/lib:\n"
     ]
    }
   ],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import Tuple, List, Any, Dict, Callable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c7223",
   "metadata": {},
   "source": [
    "## PyTorch / fast.ai like Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7328e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "    def __len__(self):\n",
    "        return jnp.shape(self.X)[0]\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i,:], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb809fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, dataset: Dataset, batchsize=32, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.shuffle = shuffle\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.dataset), self.batchsize): \n",
    "            yield self.dataset[i:i+self.batchsize]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51fe6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477c4a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras.datasets.fashion_mnist.load_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\"Loads the Fashion-MNIST dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories,\u001b[0m\n",
      "\u001b[0;34m  along with a test set of 10,000 images. This dataset can be used as\u001b[0m\n",
      "\u001b[0;34m  a drop-in replacement for MNIST.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  The classes are:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  | Label | Description |\u001b[0m\n",
      "\u001b[0;34m  |:-----:|-------------|\u001b[0m\n",
      "\u001b[0;34m  |   0   | T-shirt/top |\u001b[0m\n",
      "\u001b[0;34m  |   1   | Trouser     |\u001b[0m\n",
      "\u001b[0;34m  |   2   | Pullover    |\u001b[0m\n",
      "\u001b[0;34m  |   3   | Dress       |\u001b[0m\n",
      "\u001b[0;34m  |   4   | Coat        |\u001b[0m\n",
      "\u001b[0;34m  |   5   | Sandal      |\u001b[0m\n",
      "\u001b[0;34m  |   6   | Shirt       |\u001b[0m\n",
      "\u001b[0;34m  |   7   | Sneaker     |\u001b[0m\n",
      "\u001b[0;34m  |   8   | Bag         |\u001b[0m\n",
      "\u001b[0;34m  |   9   | Ankle boot  |\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Returns:\u001b[0m\n",
      "\u001b[0;34m    Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **x_train**: uint8 NumPy array of grayscale image data with shapes\u001b[0m\n",
      "\u001b[0;34m    `(60000, 28, 28)`, containing the training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **y_train**: uint8 NumPy array of labels (integers in range 0-9)\u001b[0m\n",
      "\u001b[0;34m    with shape `(60000,)` for the training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **x_test**: uint8 NumPy array of grayscale image data with shapes\u001b[0m\n",
      "\u001b[0;34m    (10000, 28, 28), containing the test data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **y_test**: uint8 NumPy array of labels (integers in range 0-9)\u001b[0m\n",
      "\u001b[0;34m    with shape `(10000,)` for the test data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  ```python\u001b[0m\n",
      "\u001b[0;34m  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\u001b[0m\n",
      "\u001b[0;34m  assert x_train.shape == (60000, 28, 28)\u001b[0m\n",
      "\u001b[0;34m  assert x_test.shape == (10000, 28, 28)\u001b[0m\n",
      "\u001b[0;34m  assert y_train.shape == (60000,)\u001b[0m\n",
      "\u001b[0;34m  assert y_test.shape == (10000,)\u001b[0m\n",
      "\u001b[0;34m  ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  License:\u001b[0m\n",
      "\u001b[0;34m    The copyright for Fashion-MNIST is held by Zalando SE.\u001b[0m\n",
      "\u001b[0;34m    Fashion-MNIST is licensed under the [MIT license](\u001b[0m\n",
      "\u001b[0;34m    https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fashion-mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;34m'train-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;34m't10k-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't10k-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlbpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimgpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mimgpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlbpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimgpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mimgpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.8/site-packages/keras/datasets/fashion_mnist.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist.load_data??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c49dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc06bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Dataloader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "813f493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n"
     ]
    }
   ],
   "source": [
    "for X, y in dataloader:\n",
    "    print(X.shape, y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-language",
   "metadata": {},
   "source": [
    "## Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377559ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module: pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8b9d2",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0c53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    w: jnp.ndarray \n",
    "    b: jnp.ndarray\n",
    "    ni: int \n",
    "    no: int \n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, seed=1234):\n",
    "        self.ni = num_inputs \n",
    "        self.no = num_outputs \n",
    "        key = jax.random.PRNGKey(seed)\n",
    "        self.w = jax.random.normal(key, (num_inputs, num_outputs)) * jnp.sqrt(2.0 / num_inputs)\n",
    "        self.b = jnp.zeros(num_outputs)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return jnp.dot(x, self.w) + self.b\n",
    "        \n",
    "    def params(self):\n",
    "        return {'b': self.b, 'w': self.w}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8143a664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2276616]\n"
     ]
    }
   ],
   "source": [
    "l = Linear(2, 1)\n",
    "x = np.random.randn(2)\n",
    "y = l(x)\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af8158d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(model, X, y):\n",
    "    preds = jax.vmap(model)(X)\n",
    "    return jnp.mean((preds - y)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c84e6e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.035294\n",
      "0.523962\n"
     ]
    }
   ],
   "source": [
    "print(mse(l, x, 2.0))\n",
    "print(mse(l, np.random.randn(10, 2), np.random.randn(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2280d8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument '<__main__.Linear object at 0x7f9b4ac74b50>' of type <class '__main__.Linear'> is not a valid JAX type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_129011/2465860446.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmse_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmse_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_check_arg\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m   2972\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2973\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_valid_jaxtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2974\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Argument '{arg}' of type {type(arg)} is not a valid JAX type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2976\u001b[0m \u001b[0;31m# TODO(mattjj,necula): this duplicates code in core.valid_jaxtype, but one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument '<__main__.Linear object at 0x7f9b4ac74b50>' of type <class '__main__.Linear'> is not a valid JAX type."
     ]
    }
   ],
   "source": [
    "mse_grad = jax.grad(mse)\n",
    "mse_grad(l, x, 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fce192",
   "metadata": {},
   "source": [
    "To get this to work, the `Linear` class must be registered as a pytree.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b38d3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.tree_util.register_pytree_node_class\n",
    "class Linear(Module):\n",
    "    w: jnp.ndarray \n",
    "    b: jnp.ndarray\n",
    "    ni: int \n",
    "    no: int \n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, build=True, seed=1234):\n",
    "        self.ni = num_inputs \n",
    "        self.no = num_outputs \n",
    "        # want to add seed as internal object\n",
    "        if build:\n",
    "            key = jax.random.PRNGKey(seed)\n",
    "            self.w = jax.random.normal(key, (num_inputs, num_outputs)) * jnp.sqrt(2.0 / num_inputs)\n",
    "            self.b = jnp.zeros(num_outputs)\n",
    "    \n",
    "    def merge(self, params):\n",
    "        self.w, self.b = params\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Linear(num_inputs={self.ni}, num_outputs={self.no})'\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return jnp.dot(x, self.w) + self.b\n",
    "        \n",
    "    def params(self):\n",
    "        return {'b': self.b, 'w': self.w}\n",
    "\n",
    "    def tree_flatten(self):\n",
    "        return [self.w, self.b], [self.ni, self.no]\n",
    "\n",
    "    @classmethod\n",
    "    def tree_unflatten(cls, aux_data, children):\n",
    "        layer = cls(*aux_data, build=False)\n",
    "        layer.merge(params=children)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e0498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = Linear(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44dc2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, extra_stuff = lin.tree_flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1be4bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin2 = Linear.tree_unflatten(extra_stuff, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4788c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43957582]\n",
      " [-0.26563603]]\n",
      "[[ 0.43957582]\n",
      " [-0.26563603]]\n"
     ]
    }
   ],
   "source": [
    "print(lin.w)\n",
    "print(lin2.w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4609b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@jax.value_and_grad\n",
    "def mse(model, X, y):\n",
    "    preds = jax.vmap(model)(X)\n",
    "    return jnp.mean((preds - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a924cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7428839 Linear(num_inputs=2, num_outputs=1)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randn(10, 2)\n",
    "y = np.random.randn(10)\n",
    "\n",
    "loss, g_loss = mse(lin, X, y)\n",
    "print(loss, g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edcb6098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ni': 2,\n",
       " 'no': 1,\n",
       " 'w': DeviceArray([[ 1.4666067],\n",
       "              [-0.3670275]], dtype=float32),\n",
       " 'b': DeviceArray([-0.55795026], dtype=float32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cbf1732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([DeviceArray([[ 1.4666067],\n",
       "               [-0.3670275]], dtype=float32),\n",
       "  DeviceArray([-0.55795026], dtype=float32)],\n",
       " PyTreeDef(CustomNode(<class '__main__.Linear'>[[2, 1]], [*, *])))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_util.tree_flatten(g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acecd62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()['Linear'].__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dadd9d",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e036946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x: jnp.ndarray): \n",
    "    return jnp.reshape(x, -1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c5c167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: jnp.ndarray): \n",
    "    return jnp.clip(x, a_min=0)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f3a1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10,10)\n",
    "assert jnp.all(jnp.isclose(relu(x), jax.nn.relu(x))), 'test failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e231d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: jnp.ndarray):\n",
    "    ex = jnp.exp(x)\n",
    "    return ex / jnp.sum(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "352fe9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10)\n",
    "assert jnp.all(jnp.isclose(softmax(x), jax.nn.softmax(x))), 'test failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81d624ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "_registry = {\n",
    "    flatten.__name__: flatten,\n",
    "    softmax.__name__: softmax,\n",
    "    relu.__name__: relu\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb3daa",
   "metadata": {},
   "source": [
    "### Sequential Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8490f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.tree_util.register_pytree_node_class\n",
    "class Sequential(Module):\n",
    "    layers: List\n",
    "    def __init__(self, *layers):\n",
    "        self.layers = layers\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    def tree_flatten(self):\n",
    "        aux_data, children = [], []\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Module):\n",
    "                params, extra_stuff = layer.tree_flatten()\n",
    "                aux_data.append([layer.__class__.__name__] + extra_stuff)\n",
    "                children.append(params) \n",
    "            elif callable(layer):\n",
    "                # a layer function that doesn't have any paramerers ...\n",
    "                aux_data.append(layer.__name__)\n",
    "                children.append(None)    \n",
    "        return children, aux_data\n",
    "    @classmethod\n",
    "    def tree_unflatten(cls, aux_data, children):\n",
    "        layers = []\n",
    "        # Want a more generic way to unflatten\n",
    "        for params, spec in zip(children, aux_data):\n",
    "            if isinstance(spec, list):\n",
    "                layer_name, *args = spec\n",
    "                if layer_name == 'Linear':\n",
    "                    layers.append(Linear.tree_unflatten(args, params))   \n",
    "            elif isinstance(spec, str) and spec in _registry:\n",
    "                layers.append(_registry[spec])\n",
    "        return Sequential(*layers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e871ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flatten', ['Linear', 784, 128], 'relu', ['Linear', 128, 10], 'softmax']\n",
      "[None, [DeviceArray([[-0.00503162, -0.11710759,  0.05479915, ..., -0.07662067,\n",
      "              -0.03762808,  0.037621  ],\n",
      "             [-0.02311066,  0.00427538,  0.06703123, ...,  0.05820996,\n",
      "              -0.03371886, -0.0653995 ],\n",
      "             [-0.03936624,  0.08184296, -0.00103856, ..., -0.02543773,\n",
      "               0.00404367,  0.10533019],\n",
      "             ...,\n",
      "             [-0.05674443,  0.01220774, -0.04277196, ...,  0.00793091,\n",
      "              -0.03246848,  0.05214054],\n",
      "             [-0.10229313, -0.04473471, -0.05902693, ..., -0.026743  ,\n",
      "               0.01399903, -0.02305236],\n",
      "             [ 0.02624378, -0.040582  ,  0.04346804, ..., -0.0069246 ,\n",
      "               0.04329436,  0.07048796]], dtype=float32), DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)], None, [DeviceArray([[-0.01355871,  0.03681665, -0.03254633, ...,  0.08429167,\n",
      "              -0.23054102, -0.17765395],\n",
      "             [ 0.10870937, -0.09912576, -0.15005781, ..., -0.02846045,\n",
      "              -0.17202236,  0.05921352],\n",
      "             [-0.04855632, -0.1232295 , -0.08703142, ..., -0.01804219,\n",
      "              -0.05857573, -0.05169024],\n",
      "             ...,\n",
      "             [-0.04422821,  0.02535993, -0.09997344, ..., -0.15334168,\n",
      "              -0.07498863, -0.08412767],\n",
      "             [-0.10158557,  0.035592  , -0.01597822, ..., -0.17800951,\n",
      "               0.01484985, -0.03984371],\n",
      "             [ 0.10285417, -0.07429263, -0.03157486, ..., -0.09978219,\n",
      "               0.09220438, -0.01050255]], dtype=float32), DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)], None]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fashion_mnist_mlp():\n",
    "    model = Sequential(\n",
    "        flatten,\n",
    "        Linear(784, 128),\n",
    "        relu,\n",
    "        Linear(128, 10),\n",
    "        softmax   \n",
    "    )\n",
    "\n",
    "    return model \n",
    "\n",
    "\n",
    "model = fashion_mnist_mlp()\n",
    "params, extra_stuff = model.tree_flatten()\n",
    "print(extra_stuff)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-spirit",
   "metadata": {},
   "source": [
    "## Cross-entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83a6e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.value_and_grad\n",
    "def cross_entropy(model, X, y, num_cats=10):\n",
    "    y_one_hot = jax.nn.one_hot(y, num_cats)\n",
    "    log_softmax = jnp.log(jax.vmap(model)(X))\n",
    "    return -jnp.mean(log_softmax * y_one_hot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf096acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31954172\n"
     ]
    }
   ],
   "source": [
    "\n",
    "value, grads = cross_entropy(model, np.random.randn(5, 28, 28), [1,0,1,1,0])\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae5c4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_model = jax.tree_util.tree_map(lambda p, g: p - 1e-3*g, model, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2e382c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert jnp.all(jnp.isclose(updated_model.layers[1].w, model.layers[1].w - 1e-3*grads.layers[1].w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be35ef",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db693299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer: pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c353f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    def __init__(self, model, lr=1e-3):\n",
    "        self.lr = lr \n",
    "    def step(self, model, grads):\n",
    "        return jax.tree_map(lambda p, g: p - self.lr*g, model, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "67d1a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "    def __init__(self, model, lr=1e-3, v_decay=0.9, s_decay=0.999, eps=1e-8):\n",
    "        self.lr, self.v_decay, self.s_decay, self.eps = lr, v_decay, s_decay, eps\n",
    "        self.v = jax.tree_map(lambda x: jnp.zeros_like(x), model) \n",
    "        self.s = jax.tree_map(lambda x: jnp.zeros_like(x), model)\n",
    "        self.k = 0 \n",
    "    def step(self, model, grads):\n",
    "        lr, v_decay, s_decay, eps = self.lr, self.v_decay, self.s_decay, self.eps\n",
    "        k = self.k = self.k+1\n",
    "        self.v = jax.tree_map(lambda v, g: v_decay*v +(1-v_decay)*g, self.v, grads)\n",
    "        self.s = jax.tree_map(lambda s, g: s_decay*s +(1-s_decay)*g*g, self.s, grads)\n",
    "        v_hat = jax.tree_map(lambda v: v / (1-v_decay**k), self.v)\n",
    "        s_hat = jax.tree_map(lambda s: s / (1-s_decay**k), self.s)\n",
    "        new_model = jax.tree_map(lambda params, v_hat, s_hat: params - (lr*v_hat)/(jnp.sqrt(s_hat) + eps), model, v_hat, s_hat)\n",
    "        return new_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-knock",
   "metadata": {},
   "source": [
    "## Training Loop  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89dc3d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 47.87\n",
      "Epoch 1: 66.56\n",
      "Epoch 2: 69.68\n",
      "Epoch 3: 72.04\n",
      "Epoch 4: 73.66\n",
      "Epoch 5: 75.04\n",
      "Epoch 6: 76.17\n",
      "Epoch 7: 77.09\n",
      "Epoch 8: 77.82\n",
      "Epoch 9: 78.55\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(X_train, y_train)\n",
    "dataloader = Dataloader(dataset, batchsize=64)\n",
    "model = fashion_mnist_mlp()\n",
    "num_epochs, lr = 10, 1e-2\n",
    "opt = SGD(model, lr=lr)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    epoch_correct_prediction_count = 0\n",
    "    epoch_loss = 0.0\n",
    "    num_training_examples = 0\n",
    "    for X, y in dataloader:\n",
    "        # evaluate the model\n",
    "        loss, grad = cross_entropy(model, X, y)\n",
    "        \n",
    "        # update the model using gradient descent\n",
    "        model = opt.step(model, grad)\n",
    "\n",
    "        # metrics\n",
    "        y_preds = jnp.argmax(jax.vmap(model)(X), axis=1)\n",
    "        correct = jnp.sum(y_preds == y)\n",
    "        \n",
    "        epoch_correct_prediction_count += correct\n",
    "        epoch_loss += loss \n",
    "    \n",
    "        minibatch_size = jnp.shape(X)[0]\n",
    "        num_training_examples += minibatch_size\n",
    "\n",
    "    epoch_accuracy = epoch_correct_prediction_count / num_training_examples\n",
    "    epoch_loss = epoch_loss / num_training_examples\n",
    "\n",
    "    print(f'Epoch {i}: {100*epoch_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "495818b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 82.50\n",
      "Epoch 1: 86.81\n",
      "Epoch 2: 88.04\n",
      "Epoch 3: 88.97\n",
      "Epoch 4: 89.62\n",
      "Epoch 5: 90.18\n",
      "Epoch 6: 90.64\n",
      "Epoch 7: 91.10\n",
      "Epoch 8: 91.48\n",
      "Epoch 9: 91.78\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(X_train, y_train)\n",
    "dataloader = Dataloader(dataset, batchsize=64)\n",
    "model = fashion_mnist_mlp()\n",
    "num_epochs, lr = 10, 1e-3\n",
    "opt = Adam(model)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    epoch_correct_prediction_count = 0\n",
    "    epoch_loss = 0.0\n",
    "    num_training_examples = 0\n",
    "    for X, y in dataloader:\n",
    "        # evaluate the model\n",
    "        loss, grad = cross_entropy(model, X, y)\n",
    "        \n",
    "        # update the model using gradient descent\n",
    "        model = opt.step(model, grad)\n",
    "\n",
    "        # metrics\n",
    "        y_preds = jnp.argmax(jax.vmap(model)(X), axis=1)\n",
    "        correct = jnp.sum(y_preds == y)\n",
    "        \n",
    "        epoch_correct_prediction_count += correct\n",
    "        epoch_loss += loss \n",
    "    \n",
    "        minibatch_size = jnp.shape(X)[0]\n",
    "        num_training_examples += minibatch_size\n",
    "\n",
    "    epoch_accuracy = epoch_correct_prediction_count / num_training_examples\n",
    "    epoch_loss = epoch_loss / num_training_examples\n",
    "\n",
    "    print(f'Epoch {i}: {100*epoch_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4c652",
   "metadata": {},
   "source": [
    "## API Improvements\n",
    "\n",
    "I can't claim the credit for the API implemented in this section; it's **heavily** inspired by the excellent fastai library.  I'm not lifting code from fastai, but it's tough to avoid a great (if not optimal) design. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "602849e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (411523556.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_129011/411523556.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class Machine\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e70d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a metric, but used in the callback system\n",
    "class AccuracyTracker:\n",
    "    def __init__(self):  \n",
    "        pass\n",
    "    def on_epoch_start(self, epoch):\n",
    "        print('on_epoch_start')\n",
    "        self.epoch = epoch\n",
    "        self.correct_count = 0 \n",
    "        self.num_examples = 0 \n",
    "    def on_batch_end(self, model, X, y):\n",
    "        y_preds = jnp.argmax(jax.vmap(model)(X), axis=1)\n",
    "        self.num_examples += jnp.shape(X)[0]\n",
    "        self.correct_count += jnp.sum(y_preds == y)  \n",
    "    def on_epoch_end(self):\n",
    "        accuracy = self.correct_count / self.num_examples\n",
    "        print(f'Epoch {self.epoch}: {100*accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a554d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(datasource, optimizer, loss_fn, net, num_epochs, callbacks=[]):\n",
    "    history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for cb in callbacks: cb.on_epoch_start(epoch)\n",
    "\n",
    "        for X, y in datasource:\n",
    "            # evaluate the model\n",
    "            loss, grad = loss_fn(net, X, y)\n",
    "        \n",
    "            # update the model using gradient descent\n",
    "            net = optimizer.step(net, grad)\n",
    "            \n",
    "            for cb in callbacks: cb.on_batch_end(net, X, y)\n",
    "\n",
    "        for cb in callbacks: cb.on_epoch_end()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e8d8f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_epoch_start\n",
      "Epoch 9: 82.50\n",
      "on_epoch_start\n",
      "Epoch 9: 86.81\n",
      "on_epoch_start\n",
      "Epoch 9: 88.04\n",
      "on_epoch_start\n",
      "Epoch 9: 88.97\n",
      "on_epoch_start\n",
      "Epoch 9: 89.62\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(X_train, y_train)\n",
    "dataloader = Dataloader(dataset, batchsize=64)\n",
    "\n",
    "train(dataloader, Adam(model, lr=1e-3), cross_entropy, fashion_mnist_mlp(), num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4bb53277",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_129011/4093371536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'a'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1989ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    def before_train(self):\n",
    "        pass \n",
    "    def before_epoch(self):\n",
    "        pass \n",
    "    def before_loss(self):\n",
    "        pass \n",
    "    def after_loss(self):\n",
    "        pass \n",
    "    def before_update(self):\n",
    "        pass \n",
    "    def after_update(self):\n",
    "        pass \n",
    "    def after_batch(self):\n",
    "        pass \n",
    "    def after_epoch(self):\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b488f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a metric, but used in the callback system\n",
    "class AccuracyTracker(Callback):\n",
    "    correct_count: int \n",
    "    num_examples: int  \n",
    "    def setup(self, machine):\n",
    "        self.machine = machine \n",
    "    def before_epoch(self):\n",
    "        self.correct_count = 0 \n",
    "        self.num_examples = 0\n",
    "    def after_batch(self):\n",
    "        X, y = self.batch\n",
    "        y_preds = jnp.argmax(jax.vmap(self.net)(X), axis=1)\n",
    "        self.num_examples += jnp.shape(X)[0]\n",
    "        self.correct_count += jnp.sum(y_preds == y)  \n",
    "    def after_epoch(self):\n",
    "        accuracy = self.correct_count / self.num_examples\n",
    "        self.history.append(accuracy)\n",
    "        print(f'Epoch {self.epoch}: {100*accuracy:.2f}')\n",
    "    def __getattr__(self, attr):\n",
    "        # if the attribute can't be found in the callback, recurse down to the machine attribute\n",
    "        return getattr(self.machine, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "deb79c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "    def __init__(self, datasource, optimizer, loss_fn, net, callbacks):\n",
    "        self.datasource = datasource \n",
    "        self.optimizer = optimizer \n",
    "        self.loss_fn = loss_fn \n",
    "        self.net = net \n",
    "        self.callbacks = callbacks\n",
    "        self.history = []\n",
    "        \n",
    "        # initialize all the callbacks \n",
    "        for cb in self.callbacks: cb.setup(self)\n",
    "\n",
    "    def fit(self, num_epochs):\n",
    "        self.run_callbacks('before_train')\n",
    "        for self.epoch in range(num_epochs):\n",
    "            self.run_callbacks('before_epoch')\n",
    "\n",
    "            for self.batch in self.datasource:\n",
    "                X, y = self.batch\n",
    "                # evaluate the model\n",
    "                self.run_callbacks('before_loss')\n",
    "                self.loss, self.grad = self.loss_fn(self.net, X, y)\n",
    "                self.run_callbacks('after_loss')\n",
    "\n",
    "\n",
    "                # update the model using gradient descent\n",
    "                self.run_callbacks('before_update')\n",
    "                self.net = self.optimizer.step(self.net, self.grad)\n",
    "                self.run_callbacks('after_update')\n",
    "\n",
    "                self.run_callbacks('after_batch')\n",
    "            self.run_callbacks('after_epoch')\n",
    "        return None\n",
    "    \n",
    "    def run_callbacks(self, name):\n",
    "        for cb in self.callbacks: getattr(cb, name)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "883ecd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 82.50\n",
      "Epoch 1: 86.81\n",
      "Epoch 2: 88.04\n",
      "Epoch 3: 88.97\n",
      "Epoch 4: 89.62\n",
      "Epoch 5: 90.18\n",
      "Epoch 6: 90.64\n",
      "Epoch 7: 91.10\n",
      "Epoch 8: 91.48\n",
      "Epoch 9: 91.78\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(X_train, y_train)\n",
    "dataloader = Dataloader(dataset, batchsize=64)\n",
    "net = fashion_mnist_mlp()\n",
    "machine = Machine(dataloader, Adam(net, lr=1e-3), cross_entropy, net, callbacks=[AccuracyTracker()])\n",
    "results = machine.fit(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-finder",
   "metadata": {},
   "source": [
    "## Performance Curve\n",
    "\n",
    "Let's see the trend in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "edd6d1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9b241942e0>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(machine.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-hudson",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1bd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9eb3d55570fa83a5d0e75ab0fc9e29d7692aa2022c5c86ae3b4c36003072d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
