{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "direct-series",
   "metadata": {},
   "source": [
    "# Fashion MNIST using Linear Layers with JAX\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]\n",
    "- image: images/chart-preview.png\n",
    "- hide: true\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "burning-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 21:52:53.905857: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/bin:/usr/local/lib:\n"
     ]
    }
   ],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import Tuple, List, Any, Dict, Callable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c7223",
   "metadata": {},
   "source": [
    "## PyTorch / fast.ai like Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7328e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "    def __len__(self):\n",
    "        return jnp.shape(self.X)[0]\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i,:], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb809fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, dataset: Dataset, batchsize=32, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.shuffle = shuffle\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.dataset), self.batchsize): \n",
    "            yield self.dataset[i:i+self.batchsize]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51fe6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477c4a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras.datasets.fashion_mnist.load_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\"Loads the Fashion-MNIST dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories,\u001b[0m\n",
      "\u001b[0;34m  along with a test set of 10,000 images. This dataset can be used as\u001b[0m\n",
      "\u001b[0;34m  a drop-in replacement for MNIST.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  The classes are:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  | Label | Description |\u001b[0m\n",
      "\u001b[0;34m  |:-----:|-------------|\u001b[0m\n",
      "\u001b[0;34m  |   0   | T-shirt/top |\u001b[0m\n",
      "\u001b[0;34m  |   1   | Trouser     |\u001b[0m\n",
      "\u001b[0;34m  |   2   | Pullover    |\u001b[0m\n",
      "\u001b[0;34m  |   3   | Dress       |\u001b[0m\n",
      "\u001b[0;34m  |   4   | Coat        |\u001b[0m\n",
      "\u001b[0;34m  |   5   | Sandal      |\u001b[0m\n",
      "\u001b[0;34m  |   6   | Shirt       |\u001b[0m\n",
      "\u001b[0;34m  |   7   | Sneaker     |\u001b[0m\n",
      "\u001b[0;34m  |   8   | Bag         |\u001b[0m\n",
      "\u001b[0;34m  |   9   | Ankle boot  |\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Returns:\u001b[0m\n",
      "\u001b[0;34m    Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **x_train**: uint8 NumPy array of grayscale image data with shapes\u001b[0m\n",
      "\u001b[0;34m    `(60000, 28, 28)`, containing the training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **y_train**: uint8 NumPy array of labels (integers in range 0-9)\u001b[0m\n",
      "\u001b[0;34m    with shape `(60000,)` for the training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **x_test**: uint8 NumPy array of grayscale image data with shapes\u001b[0m\n",
      "\u001b[0;34m    (10000, 28, 28), containing the test data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **y_test**: uint8 NumPy array of labels (integers in range 0-9)\u001b[0m\n",
      "\u001b[0;34m    with shape `(10000,)` for the test data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  ```python\u001b[0m\n",
      "\u001b[0;34m  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\u001b[0m\n",
      "\u001b[0;34m  assert x_train.shape == (60000, 28, 28)\u001b[0m\n",
      "\u001b[0;34m  assert x_test.shape == (10000, 28, 28)\u001b[0m\n",
      "\u001b[0;34m  assert y_train.shape == (60000,)\u001b[0m\n",
      "\u001b[0;34m  assert y_test.shape == (10000,)\u001b[0m\n",
      "\u001b[0;34m  ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  License:\u001b[0m\n",
      "\u001b[0;34m    The copyright for Fashion-MNIST is held by Zalando SE.\u001b[0m\n",
      "\u001b[0;34m    Fashion-MNIST is licensed under the [MIT license](\u001b[0m\n",
      "\u001b[0;34m    https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fashion-mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;34m'train-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;34m't10k-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't10k-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlbpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimgpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mimgpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlbpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimgpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mimgpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.8/site-packages/keras/datasets/fashion_mnist.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist.load_data??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c49dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc06bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Dataloader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "813f493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n",
      "(32, 28, 28) (32,)\n"
     ]
    }
   ],
   "source": [
    "for X, y in dataloader:\n",
    "    print(X.shape, y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-language",
   "metadata": {},
   "source": [
    "## Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377559ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module: pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8b9d2",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0c53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    w: jnp.ndarray \n",
    "    b: jnp.ndarray\n",
    "    ni: int \n",
    "    no: int \n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, seed=1234):\n",
    "        self.ni = num_inputs \n",
    "        self.no = num_outputs \n",
    "        key = jax.random.PRNGKey(seed)\n",
    "        self.w = jax.random.normal(key, (num_inputs, num_outputs)) * jnp.sqrt(2.0 / num_inputs)\n",
    "        self.b = jnp.zeros(num_outputs)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return jnp.dot(x, self.w) + self.b\n",
    "        \n",
    "    def params(self):\n",
    "        return {'b': self.b, 'w': self.w}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8143a664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2276616]\n"
     ]
    }
   ],
   "source": [
    "l = Linear(2, 1)\n",
    "x = np.random.randn(2)\n",
    "y = l(x)\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af8158d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(model, X, y):\n",
    "    preds = jax.vmap(model)(X)\n",
    "    return jnp.mean((preds - y)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c84e6e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.035294\n",
      "0.523962\n"
     ]
    }
   ],
   "source": [
    "print(mse(l, x, 2.0))\n",
    "print(mse(l, np.random.randn(10, 2), np.random.randn(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2280d8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument '<__main__.Linear object at 0x7f9b4ac74b50>' of type <class '__main__.Linear'> is not a valid JAX type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_129011/2465860446.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmse_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmse_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_check_arg\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m   2972\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2973\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_valid_jaxtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2974\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Argument '{arg}' of type {type(arg)} is not a valid JAX type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2976\u001b[0m \u001b[0;31m# TODO(mattjj,necula): this duplicates code in core.valid_jaxtype, but one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument '<__main__.Linear object at 0x7f9b4ac74b50>' of type <class '__main__.Linear'> is not a valid JAX type."
     ]
    }
   ],
   "source": [
    "mse_grad = jax.grad(mse)\n",
    "mse_grad(l, x, 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fce192",
   "metadata": {},
   "source": [
    "To get this to work, the `Linear` class must be registered as a pytree.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b38d3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.tree_util.register_pytree_node_class\n",
    "class Linear(Module):\n",
    "    w: jnp.ndarray \n",
    "    b: jnp.ndarray\n",
    "    ni: int \n",
    "    no: int \n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, build=True, seed=1234):\n",
    "        self.ni = num_inputs \n",
    "        self.no = num_outputs \n",
    "        # want to add seed as internal object\n",
    "        if build:\n",
    "            key = jax.random.PRNGKey(seed)\n",
    "            self.w = jax.random.normal(key, (num_inputs, num_outputs)) * jnp.sqrt(2.0 / num_inputs)\n",
    "            self.b = jnp.zeros(num_outputs)\n",
    "    \n",
    "    def merge(self, params):\n",
    "        self.w, self.b = params\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Linear(num_inputs={self.ni}, num_outputs={self.no})'\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return jnp.dot(x, self.w) + self.b\n",
    "        \n",
    "    def params(self):\n",
    "        return {'b': self.b, 'w': self.w}\n",
    "\n",
    "    def tree_flatten(self):\n",
    "        return [self.w, self.b], [self.ni, self.no]\n",
    "\n",
    "    @classmethod\n",
    "    def tree_unflatten(cls, aux_data, children):\n",
    "        layer = cls(*aux_data, build=False)\n",
    "        layer.merge(params=children)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e0498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = Linear(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44dc2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, extra_stuff = lin.tree_flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1be4bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin2 = Linear.tree_unflatten(extra_stuff, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4788c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43957582]\n",
      " [-0.26563603]]\n",
      "[[ 0.43957582]\n",
      " [-0.26563603]]\n"
     ]
    }
   ],
   "source": [
    "print(lin.w)\n",
    "print(lin2.w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4609b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@jax.value_and_grad\n",
    "def mse(model, X, y):\n",
    "    preds = jax.vmap(model)(X)\n",
    "    return jnp.mean((preds - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a924cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7428839 Linear(num_inputs=2, num_outputs=1)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randn(10, 2)\n",
    "y = np.random.randn(10)\n",
    "\n",
    "loss, g_loss = mse(lin, X, y)\n",
    "print(loss, g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edcb6098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ni': 2,\n",
       " 'no': 1,\n",
       " 'w': DeviceArray([[ 1.4666067],\n",
       "              [-0.3670275]], dtype=float32),\n",
       " 'b': DeviceArray([-0.55795026], dtype=float32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cbf1732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([DeviceArray([[ 1.4666067],\n",
       "               [-0.3670275]], dtype=float32),\n",
       "  DeviceArray([-0.55795026], dtype=float32)],\n",
       " PyTreeDef(CustomNode(<class '__main__.Linear'>[[2, 1]], [*, *])))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_util.tree_flatten(g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acecd62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()['Linear'].__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dadd9d",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e036946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x: jnp.ndarray): \n",
    "    return jnp.reshape(x, -1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c5c167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: jnp.ndarray): \n",
    "    return jnp.clip(x, a_min=0)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f3a1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10,10)\n",
    "assert jnp.all(jnp.isclose(relu(x), jax.nn.relu(x))), 'test failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e231d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: jnp.ndarray):\n",
    "    ex = jnp.exp(x)\n",
    "    return ex / jnp.sum(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "352fe9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10)\n",
    "assert jnp.all(jnp.isclose(softmax(x), jax.nn.softmax(x))), 'test failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81d624ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "_registry = {\n",
    "    flatten.__name__: flatten,\n",
    "    softmax.__name__: softmax,\n",
    "    relu.__name__: relu\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb3daa",
   "metadata": {},
   "source": [
    "### Sequential Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8490f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.tree_util.register_pytree_node_class\n",
    "class Sequential(Module):\n",
    "    layers: List\n",
    "    def __init__(self, *layers):\n",
    "        self.layers = layers\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    def tree_flatten(self):\n",
    "        aux_data, children = [], []\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Module):\n",
    "                params, extra_stuff = layer.tree_flatten()\n",
    "                aux_data.append([layer.__class__.__name__] + extra_stuff)\n",
    "                children.append(params) \n",
    "            elif callable(layer):\n",
    "                # a layer function that doesn't have any paramerers ...\n",
    "                aux_data.append(layer.__name__)\n",
    "                children.append(None)    \n",
    "        return children, aux_data\n",
    "    @classmethod\n",
    "    def tree_unflatten(cls, aux_data, children):\n",
    "        layers = []\n",
    "        # Need a bettern way to unflatten a sequential structure, more flexible at least...\n",
    "        for params, spec in zip(children, aux_data):\n",
    "            if isinstance(spec, list):\n",
    "                layer_name, *args = spec\n",
    "                if layer_name == 'Linear':\n",
    "                    layers.append(Linear.tree_unflatten(args, params))   \n",
    "            elif isinstance(spec, str) and spec in _registry:\n",
    "                layers.append(_registry[spec])\n",
    "        return Sequential(*layers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e871ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flatten', ['Linear', 784, 128], 'relu', ['Linear', 128, 10], 'softmax']\n",
      "[None, [DeviceArray([[-0.00503162, -0.11710759,  0.05479915, ..., -0.07662067,\n",
      "              -0.03762808,  0.037621  ],\n",
      "             [-0.02311066,  0.00427538,  0.06703123, ...,  0.05820996,\n",
      "              -0.03371886, -0.0653995 ],\n",
      "             [-0.03936624,  0.08184296, -0.00103856, ..., -0.02543773,\n",
      "               0.00404367,  0.10533019],\n",
      "             ...,\n",
      "             [-0.05674443,  0.01220774, -0.04277196, ...,  0.00793091,\n",
      "              -0.03246848,  0.05214054],\n",
      "             [-0.10229313, -0.04473471, -0.05902693, ..., -0.026743  ,\n",
      "               0.01399903, -0.02305236],\n",
      "             [ 0.02624378, -0.040582  ,  0.04346804, ..., -0.0069246 ,\n",
      "               0.04329436,  0.07048796]], dtype=float32), DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)], None, [DeviceArray([[-0.01355871,  0.03681665, -0.03254633, ...,  0.08429167,\n",
      "              -0.23054102, -0.17765395],\n",
      "             [ 0.10870937, -0.09912576, -0.15005781, ..., -0.02846045,\n",
      "              -0.17202236,  0.05921352],\n",
      "             [-0.04855632, -0.1232295 , -0.08703142, ..., -0.01804219,\n",
      "              -0.05857573, -0.05169024],\n",
      "             ...,\n",
      "             [-0.04422821,  0.02535993, -0.09997344, ..., -0.15334168,\n",
      "              -0.07498863, -0.08412767],\n",
      "             [-0.10158557,  0.035592  , -0.01597822, ..., -0.17800951,\n",
      "               0.01484985, -0.03984371],\n",
      "             [ 0.10285417, -0.07429263, -0.03157486, ..., -0.09978219,\n",
      "               0.09220438, -0.01050255]], dtype=float32), DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)], None]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fashion_mnist_mlp():\n",
    "    model = Sequential(\n",
    "        flatten,\n",
    "        Linear(784, 128),\n",
    "        relu,\n",
    "        Linear(128, 10),\n",
    "        softmax   \n",
    "    )\n",
    "\n",
    "    return model \n",
    "\n",
    "\n",
    "model = fashion_mnist_mlp()\n",
    "params, extra_stuff = model.tree_flatten()\n",
    "print(extra_stuff)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-spirit",
   "metadata": {},
   "source": [
    "## Cross-entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83a6e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.value_and_grad\n",
    "def cross_entropy(model, X, y, num_cats=10):\n",
    "    y_one_hot = jax.nn.one_hot(y, num_cats)\n",
    "    log_softmax = jnp.log(jax.vmap(model)(X))\n",
    "    return -jnp.mean(log_softmax * y_one_hot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf096acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31954172\n"
     ]
    }
   ],
   "source": [
    "\n",
    "value, grads = cross_entropy(model, np.random.randn(5, 28, 28), [1,0,1,1,0])\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c399840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 4, 6], [2, 4], [2, 4, 6, 8]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists = [\n",
    "    [1, 2, 3],\n",
    "    [1, 2],\n",
    "    [1, 2, 3, 4]\n",
    "]\n",
    "\n",
    "jax.tree_map(lambda x: x*2, list_of_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae5c4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_model = jax.tree_util.tree_map(lambda p, g: p - 1e-3*g, model, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2e382c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert jnp.all(jnp.isclose(updated_model.layers[1].w, model.layers[1].w - 1e-3*grads.layers[1].w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be35ef",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db693299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer: pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c353f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    def __init__(self, model, lr=1e-3):\n",
    "        self.lr = lr \n",
    "    def step(self, model, grads):\n",
    "        return jax.tree_map(lambda p, g: p - self.lr*g, model, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67d1a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "    def __init__(self, model, lr=1e-3, v_decay=0.9, s_decay=0.999, eps=1e-8):\n",
    "        self.lr, self.v_decay, self.s_decay, self.eps = lr, v_decay, s_decay, eps\n",
    "        self.v = jax.tree_map(lambda x: jnp.zeros_like(x), model) \n",
    "        self.s = jax.tree_map(lambda x: jnp.zeros_like(x), model)\n",
    "        self.k = 0 \n",
    "    def step(self, model, grads):\n",
    "        lr, v_decay, s_decay, eps = self.lr, self.v_decay, self.s_decay, self.eps\n",
    "        k = self.k = self.k+1\n",
    "        self.v = jax.tree_map(lambda v, g: v_decay*v +(1-v_decay)*g, self.v, grads)\n",
    "        self.s = jax.tree_map(lambda s, g: s_decay*s +(1-s_decay)*g*g, self.s, grads)\n",
    "        v_hat = jax.tree_map(lambda v: v / (1-v_decay**k), self.v)\n",
    "        s_hat = jax.tree_map(lambda s: s / (1-s_decay**k), self.s)\n",
    "        result = jax.tree_map(lambda params, v_hat, s_hat: params - (lr*v_hat)/(jnp.sqrt(s_hat) + eps), model, v_hat, s_hat)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90742ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b22ddfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Sequential at 0x7f9b47b31790>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "charged-knock",
   "metadata": {},
   "source": [
    "## Training Loop  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89dc3d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 47.87\n",
      "Epoch 1: 66.56\n",
      "Epoch 2: 69.68\n",
      "Epoch 3: 72.04\n",
      "Epoch 4: 73.66\n",
      "Epoch 5: 75.04\n",
      "Epoch 6: 76.17\n",
      "Epoch 7: 77.09\n",
      "Epoch 8: 77.82\n",
      "Epoch 9: 78.55\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(X_train, y_train)\n",
    "dataloader = Dataloader(dataset, batchsize=64)\n",
    "model = fashion_mnist_mlp()\n",
    "num_epochs, lr = 10, 1e-2\n",
    "opt = SGD(model, lr=lr)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    epoch_correct_prediction_count = 0\n",
    "    epoch_loss = 0.0\n",
    "    num_training_examples = 0\n",
    "    for X, y in dataloader:\n",
    "        # evaluate the model\n",
    "        loss, grad = cross_entropy(model, X, y)\n",
    "        \n",
    "        # update the model using gradient descent\n",
    "        model = opt.step(model, grad)\n",
    "\n",
    "        # metrics\n",
    "        y_preds = jnp.argmax(jax.vmap(model)(X), axis=1)\n",
    "        correct = jnp.sum(y_preds == y)\n",
    "        \n",
    "        epoch_correct_prediction_count += correct\n",
    "        epoch_loss += loss \n",
    "    \n",
    "        minibatch_size = jnp.shape(X)[0]\n",
    "        num_training_examples += minibatch_size\n",
    "\n",
    "    epoch_accuracy = epoch_correct_prediction_count / num_training_examples\n",
    "    epoch_loss = epoch_loss / num_training_examples\n",
    "\n",
    "    print(f'Epoch {i}: {100*epoch_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "495818b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 82.50\n",
      "Epoch 1: 86.81\n",
      "Epoch 2: 88.04\n",
      "Epoch 3: 88.97\n",
      "Epoch 4: 89.62\n",
      "Epoch 5: 90.18\n",
      "Epoch 6: 90.64\n",
      "Epoch 7: 91.10\n",
      "Epoch 8: 91.48\n",
      "Epoch 9: 91.78\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(X_train, y_train)\n",
    "dataloader = Dataloader(dataset, batchsize=64)\n",
    "model = fashion_mnist_mlp()\n",
    "num_epochs, lr = 10, 1e-3\n",
    "opt = Adam(model)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    epoch_correct_prediction_count = 0\n",
    "    epoch_loss = 0.0\n",
    "    num_training_examples = 0\n",
    "    for X, y in dataloader:\n",
    "        # evaluate the model\n",
    "        loss, grad = cross_entropy(model, X, y)\n",
    "        \n",
    "        # update the model using gradient descent\n",
    "        model = opt.step(model, grad)\n",
    "\n",
    "        # metrics\n",
    "        y_preds = jnp.argmax(jax.vmap(model)(X), axis=1)\n",
    "        correct = jnp.sum(y_preds == y)\n",
    "        \n",
    "        epoch_correct_prediction_count += correct\n",
    "        epoch_loss += loss \n",
    "    \n",
    "        minibatch_size = jnp.shape(X)[0]\n",
    "        num_training_examples += minibatch_size\n",
    "\n",
    "    epoch_accuracy = epoch_correct_prediction_count / num_training_examples\n",
    "    epoch_loss = epoch_loss / num_training_examples\n",
    "\n",
    "    print(f'Epoch {i}: {100*epoch_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4c652",
   "metadata": {},
   "source": [
    "## API Improvements\n",
    "\n",
    "Heavily inspired by fast.ai.  The **Deep Learning for Coders with fastai and PyTorch** book is great and full of great ideas and software design techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e70d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a metric, but used in the callback system\n",
    "class AccuracyTracker:\n",
    "    def __init__(self):\n",
    "        self.correct_prediction_count = 0 \n",
    "        self.num_examples = 0 \n",
    "    def on_minibatch_end(self, model, X, y):\n",
    "        y_preds = jnp.argmax(jax.vmap(model)(X), axis=1)\n",
    "        self.num_examples += jnp.shape(X)[0]\n",
    "        self.correct_count += jnp.sum(y_preds == y)  \n",
    "    def on_epoch_end(self):\n",
    "        accuracy = self.correct_count / self.num_examples\n",
    "        return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(X_train, y_train)\n",
    "dataloader = Dataloader(dataset, batchsize=64)\n",
    "model = fashion_mnist_mlp()\n",
    "num_epochs, lr = 10, 1e-3\n",
    "opt = Adam(model)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    epoch_correct_prediction_count = 0\n",
    "    epoch_loss = 0.0\n",
    "    num_training_examples = 0\n",
    "    for X, y in dataloader:\n",
    "        # evaluate the model\n",
    "        loss, grad = cross_entropy(model, X, y)\n",
    "        \n",
    "        # update the model using gradient descent\n",
    "        model = opt.step(model, grad)\n",
    "\n",
    "        for cb in callbacks:\n",
    "            cb.on_minibatch_end(model, X, y)\n",
    "            \n",
    "        # metrics\n",
    "        y_preds = jnp.argmax(jax.vmap(model)(X), axis=1)\n",
    "        correct = jnp.sum(y_preds == y)\n",
    "        \n",
    "        epoch_correct_prediction_count += correct\n",
    "        epoch_loss += loss \n",
    "    \n",
    "        minibatch_size = jnp.shape(X)[0]\n",
    "        num_training_examples += minibatch_size\n",
    "\n",
    "    epoch_accuracy = epoch_correct_prediction_count / num_training_examples\n",
    "    epoch_loss = epoch_loss / num_training_examples\n",
    "\n",
    "    print(f'Epoch {i}: {100*epoch_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-finder",
   "metadata": {},
   "source": [
    "## Performance Curve\n",
    "\n",
    "Let's see the trend in the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-hudson",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9eb3d55570fa83a5d0e75ab0fc9e29d7692aa2022c5c86ae3b4c36003072d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
