{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "painted-probe",
   "metadata": {},
   "source": [
    "# Convolutional Layer\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]\n",
    "- image: images/chart-preview.png\n",
    "- hide: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-rouge",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-ghana",
   "metadata": {},
   "source": [
    "## Let's Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "heated-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time \n",
    "\n",
    "from typing import Tuple, List, Any, Dict, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-honor",
   "metadata": {},
   "source": [
    "### Convolutional Layer\n",
    "\n",
    "The first function argument is the number of filters and the second argument is the shape of the kernel.  There are other parameters too, but I'm going to keep things simple for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "protecting-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = tf.keras.layers.Conv2D(filters=2, kernel_size=(2, 2), use_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-question",
   "metadata": {},
   "source": [
    "Arrays fed to `layer` must be a 4D tensor where the first axis is the batch size, the second axis is the width, the third axis is the height, and thr fourth axis is \n",
    "the number of input channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "physical-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = np.random.randn(4,4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-secretariat",
   "metadata": {},
   "source": [
    "Because Keras layers operate on batches of data, and not individual examples, a batch dimension must be addes to `input_image`.  To do this in numpy, take `input_image` and add a `None` in the axis you want to add:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "proper-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = input_image[None,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "improving-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = conv_layer(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "entitled-remainder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3, 3, 2])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "mounted-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = conv_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "demonstrated-titanium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w shape = (2, 2, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'w shape = {kernels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-pound",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "chinese-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(kernel, x):\n",
    "    y = np.zeros((3,3))\n",
    "    \n",
    "    y[0,0] = np.sum(kernel * x[0:2,0:2])\n",
    "    y[0,1] = np.sum(kernel * x[0:2,1:3])\n",
    "    y[0,2] = np.sum(kernel * x[0:2,2:4])\n",
    "    y[1,0] = np.sum(kernel * x[1:3,0:2])\n",
    "    y[1,1] = np.sum(kernel * x[1:3,1:3])\n",
    "    y[1,2] = np.sum(kernel * x[1:3,2:4])\n",
    "    y[2,0] = np.sum(kernel * x[2:4,0:2])\n",
    "    y[2,1] = np.sum(kernel * x[2:4,1:3])\n",
    "    y[2,2] = np.sum(kernel * x[2:4,2:4])    \n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "suffering-adjustment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(range(5), range(5)):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "unlikely-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_1(kernel, x):\n",
    "    xm, xn = x.shape \n",
    "    km, kn = kernel.shape \n",
    "    \n",
    "    y = np.zeros((xm - km + 1, xn - kn + 1))\n",
    "    \n",
    "    ym, yn = y.shape\n",
    "    for i in range(ym):\n",
    "        for j in range(yn):\n",
    "            y[i, j] = np.sum(kernel * x[i:i+km, j:j+kn]) \n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-tuning",
   "metadata": {},
   "source": [
    "Here's a faily inefficient way to duplicate the evaluation of the `conv_layer` defined in above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "random-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(input_image, kernels):\n",
    "    \n",
    "    width, height, input_chans = input_image.shape \n",
    "    km, kn, _, output_chans = kernels.shape\n",
    "    \n",
    "    width_ = width - km + 1\n",
    "    height_ = height - kn + 1 \n",
    "    \n",
    "    features = np.zeros((width_, height_, output_chans))\n",
    "\n",
    "    for out_chan in range(output_chans):\n",
    "        y = np.zeros((width_, height_))\n",
    "        for in_chan in range(input_chans):\n",
    "            y += conv2d_1(\n",
    "                kernels[:,:,in_chan, out_chan], \n",
    "                input_image[:,:,in_chan]\n",
    "            )\n",
    "        \n",
    "        # set the features\n",
    "        features[:,:,out_chan] = y\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "framed-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ = convolve(input_image, kernels)[None,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "vital-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(feature_maps, features_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-haven",
   "metadata": {},
   "source": [
    "## Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "fuzzy-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "treated-community",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 2) -> (1, 1, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "yy = pooling_layer(feature_maps)\n",
    "print(f'{feature_maps.shape} -> {yy.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "caroline-pastor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 2), dtype=float32, numpy=array([[[[0.9654248, 1.2988867]]]], dtype=float32)>"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "subtle-tract",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.89900464 -1.0616233 ]\n",
      "   [-0.10247962  1.2988867 ]\n",
      "   [-0.8515937   0.6712394 ]]\n",
      "\n",
      "  [[ 0.9654248   0.23607667]\n",
      "   [-0.43404913  0.27193436]\n",
      "   [-0.5712364  -0.73882663]]\n",
      "\n",
      "  [[ 0.6847748  -0.8419535 ]\n",
      "   [ 0.46285468  0.7197448 ]\n",
      "   [-1.3353215   0.47066653]]]], shape=(1, 3, 3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "coral-velvet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.9654248   1.2988867 ]\n",
      "   [-0.10247962  1.2988867 ]]\n",
      "\n",
      "  [[ 0.9654248   0.7197448 ]\n",
      "   [ 0.46285468  0.7197448 ]]]], shape=(1, 2, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "answering-fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.0616233   1.2988867   0.6712394 ]\n",
      " [ 0.23607667  0.27193436 -0.73882663]\n",
      " [-0.8419535   0.7197448   0.47066653]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(feature_maps[0,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "confirmed-doubt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1.2988867, 1.2988867],\n",
       "       [0.7197448, 0.7197448]], dtype=float32)>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy[0,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "pretty-growth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 3)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "naughty-catalog",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "boolean-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2D_(x, pool_size=(2,2), strides=(1,1)):\n",
    "    xm, xn = x.shape \n",
    "    pm, pn = pool_size \n",
    "    sm, sn = strides\n",
    "    \n",
    "    y = np.zeros((xm - pm + 1, xn - pn + 1))\n",
    "    ym, yn = y.shape\n",
    "    \n",
    "    ii = 0\n",
    "    for i in range(0, xm-pm+1, sm):\n",
    "        jj = 0\n",
    "        for j in range(0, xn-pn+1, sn):\n",
    "            y[ii,jj] = np.max(x[i:i+pm,j:j+pn])\n",
    "            jj += 1\n",
    "        ii += 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "chronic-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2D(x, pool_size=(2,2), strides=(1,1)):\n",
    "    xm, xn = x.shape \n",
    "    pm, pn = pool_size \n",
    "    sm, sn = strides\n",
    "    \n",
    "    y = np.zeros((xm - pm + 1, xn - pn + 1))\n",
    "    \n",
    "    ym, yn = y.shape\n",
    "    \n",
    "    for i in range(0, ym):\n",
    "        for j in range(0, yn):\n",
    "            y[i,j] = np.max(x[i:i+pm,j:j+pn])\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "accepting-enzyme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41550751 0.        ]\n",
      " [0.         0.        ]]\n",
      "[[0.41550751 0.30410219]\n",
      " [0.41602673 0.01748251]]\n",
      "[[-1.25540847  0.30410219 -0.13907104]\n",
      " [ 0.41550751  0.01748251 -0.22689558]\n",
      " [ 0.41602673 -1.1301399  -0.82329309]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(3,3)\n",
    "a = pool2D_(x)\n",
    "b = pool2D(x)\n",
    "print(a)\n",
    "print(b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "attended-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(features, pool_size=(2,2), strides=(3,3)):\n",
    "    \n",
    "    px, py = pool_size\n",
    "    width, height, chans = features.shape \n",
    "    \n",
    "    width_ = width - px + 1\n",
    "    height_ = height - py + 1 \n",
    "    \n",
    "    features_ = np.zeros((width_, height_, chans))\n",
    "\n",
    "    for chan in range(chans):\n",
    "        features_[:,:,chan] = pool2D_(features[:,:,chan], pool_size, strides)\n",
    "    \n",
    "    return features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "partial-living",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.96542478, 1.29888666],\n",
       "        [0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        ],\n",
       "        [0.        , 0.        ]]])"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling(feature_maps[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-bracelet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9eb3d55570fa83a5d0e75ab0fc9e29d7692aa2022c5c86ae3b4c36003072d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
