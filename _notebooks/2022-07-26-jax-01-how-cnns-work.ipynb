{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funky-pregnancy",
   "metadata": {},
   "source": [
    "# Checking Understanding of Convolutional and Pooling Layers\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: [jax, convolution, pooling]\n",
    "- hide: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-assumption",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The purpose of this post is to make sure I understand how convolutional and pooling layers work.  Once again, I'll use Keras to double check all my work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-abuse",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "For now, I'm just using numpy and keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "demanding-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-produce",
   "metadata": {},
   "source": [
    "First, I am going to create a small sequential model in Keras consisting of a convolutional layer followed by a max-pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "floral-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=4, kernel_size=(2, 2)),    \n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-morocco",
   "metadata": {},
   "source": [
    "Next, I want to apply the model to a random input.  After this, I'll be able to get at the weights and features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "diverse-walnut",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Mapping:  (1, 28, 28, 3) -> (1, 13, 13, 4)\n"
     ]
    }
   ],
   "source": [
    "inputs = np.random.randn(28,28,3)[np.newaxis,:,:,:]\n",
    "outputs = model(inputs)\n",
    "print(f'Feature Mapping:  {inputs.shape} -> {outputs.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-lighter",
   "metadata": {},
   "source": [
    "The `inputs` array consists of a single 28-by-28 3-channel array, with an additional axis to make it a batch.  We have to do this because models in Keras operate over batches and not single examples.  Because `Conv2D` uses 4 filters, and `MaxPool2D` preserves the number of channels, the `outputs` also has 4 channels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "environmental-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [layer.output for layer in model.layers]\n",
    "layer_output_model = tf.keras.Model(inputs=model.input, outputs=outputs)\n",
    "keras_features = layer_output_model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "champion-machinery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 27, 27, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-slave",
   "metadata": {},
   "source": [
    "### Convolutional Layer\n",
    "\n",
    "The first function argument is the number of filters and the second argument is the shape of the kernel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "mexican-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = tf.keras.layers.Conv2D(filters=2, kernel_size=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-likelihood",
   "metadata": {},
   "source": [
    "Arrays fed to `layer` must be a 4D tensor where the first axis is the batch size, the second axis is the width, the third axis is the height, and the fourth axis is \n",
    "the number of input channels.  Here we generate a batch containing a single $4\\times4$ array with 3-channels, pass it to `conv_layer` and look at the shape of output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "italian-operator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Mapping:  (1, 4, 4, 3) -> (1, 3, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "input_image = np.random.randn(1,4,4,3)\n",
    "features = conv_layer(input_batch)\n",
    "print(f'Feature Mapping:  {input_image.shape} -> {features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-sapphire",
   "metadata": {},
   "source": [
    "This means that there's still one image in the batch, but it shrunk from $4\\times4$ to $3\\times3$.  This resizing effect occurred because unless the input is padded, convolution always reduces the input by a function of it's kernel (or filter size). Also notice that the number of channels went from 3 to 2.  In general, the number of output channels will match the `filters` argument passed in to the `Conv2D` constructor.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "stunning-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels, biases = conv_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "cardiac-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels, biases = model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "turkish-toilet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernels shape = (2, 2, 3, 2), biases shape =(2,)\n"
     ]
    }
   ],
   "source": [
    "print(f'kernels shape = {kernels.shape}, biases shape ={biases.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "declared-radar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-drive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mexican-strain",
   "metadata": {},
   "source": [
    "Here's a faily inefficient way to duplicate the evaluation of the `conv_layer` defined in above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "ceramic-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv2d_v1(x, kernel):\n",
    "    xm, xn = x.shape \n",
    "    km, kn = kernel.shape \n",
    "    \n",
    "    y = np.zeros((xm - km + 1, xn - kn + 1))\n",
    "    \n",
    "    ym, yn = y.shape\n",
    "    for i in range(ym):\n",
    "        for j in range(yn):\n",
    "            y[i, j] = np.sum(kernel * x[i:i+km, j:j+kn]) \n",
    "    \n",
    "    return y\n",
    "\n",
    "def convolve_v1(input_image, kernels, biases):\n",
    "    \n",
    "    width, height, input_chans = input_image.shape \n",
    "    km, kn, _, output_chans = kernels.shape\n",
    "    \n",
    "    w = width - km + 1\n",
    "    h = height - kn + 1 \n",
    "    \n",
    "    features = np.zeros((w, h, output_chans))\n",
    "\n",
    "    for out_chan in range(output_chans):\n",
    "        y = np.zeros((w, h))\n",
    "        for in_chan in range(input_chans):\n",
    "            y += conv2d(\n",
    "                input_image[:,:,in_chan],\n",
    "                kernels[:,:,in_chan, out_chan], \n",
    "            )\n",
    "        \n",
    "        # one bias per output feature\n",
    "        features[:,:,out_chan] = y + biases[out_chan]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "international-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_v2(x, kernel):\n",
    "    xm, xn, _ = x.shape \n",
    "    km, kn, _ = kernel.shape \n",
    "    \n",
    "    y = np.zeros((xm - km + 1, xn - kn + 1))\n",
    "    \n",
    "    ym, yn = y.shape\n",
    "    for i in range(ym):\n",
    "        for j in range(yn):\n",
    "            y[i, j] = np.sum(kernel * x[i:i+km, j:j+kn,:]) \n",
    "    \n",
    "    return y\n",
    "\n",
    "def convolve_v2(features_in, kernels, biases):\n",
    "    \n",
    "    fm, fn, _ = features_in.shape \n",
    "    km, kn, _, no = kernels.shape\n",
    "    \n",
    "    fm = fm - km + 1\n",
    "    fn = fn - kn + 1 \n",
    "    \n",
    "    features_out = np.zeros((fm, fn, no))\n",
    "\n",
    "    for i in range(no):\n",
    "        features_out[:,:,i] = conv2d_v2(features_in, kernels[:,:,:,i]) + biases[i]\n",
    "    \n",
    "    return features_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "adapted-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ = convolve_v2(input_image, kernels, biases)[None,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "sunrise-steering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.57096572, -0.97925384],\n",
       "         [-1.06541922, -0.0675798 ],\n",
       "         [ 0.57326961, -0.03206957]],\n",
       "\n",
       "        [[ 1.72291908, -0.01773216],\n",
       "         [-1.19444309,  1.01715131],\n",
       "         [ 0.42115538,  0.18736924]],\n",
       "\n",
       "        [[ 1.00037184,  0.93437332],\n",
       "         [-0.83191143, -0.82429726],\n",
       "         [ 1.47947074,  0.18596377]]]])"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "adjusted-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(ll[0], features_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-accountability",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "foreign-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "above-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 2) -> (1, 1, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "yy = pooling_layer(feature_maps)\n",
    "print(f'{feature_maps.shape} -> {yy.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "agricultural-radio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 2), dtype=float32, numpy=array([[[[0.9654248, 1.2988867]]]], dtype=float32)>"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "curious-monkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.89900464 -1.0616233 ]\n",
      "   [-0.10247962  1.2988867 ]\n",
      "   [-0.8515937   0.6712394 ]]\n",
      "\n",
      "  [[ 0.9654248   0.23607667]\n",
      "   [-0.43404913  0.27193436]\n",
      "   [-0.5712364  -0.73882663]]\n",
      "\n",
      "  [[ 0.6847748  -0.8419535 ]\n",
      "   [ 0.46285468  0.7197448 ]\n",
      "   [-1.3353215   0.47066653]]]], shape=(1, 3, 3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "employed-virus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.9654248   1.2988867 ]\n",
      "   [-0.10247962  1.2988867 ]]\n",
      "\n",
      "  [[ 0.9654248   0.7197448 ]\n",
      "   [ 0.46285468  0.7197448 ]]]], shape=(1, 2, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "divine-importance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.0616233   1.2988867   0.6712394 ]\n",
      " [ 0.23607667  0.27193436 -0.73882663]\n",
      " [-0.8419535   0.7197448   0.47066653]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(feature_maps[0,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "desirable-grade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1.2988867, 1.2988867],\n",
       "       [0.7197448, 0.7197448]], dtype=float32)>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy[0,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "median-resolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 3)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "collective-arrival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "unknown-flexibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.zeros((3,3))\n",
    "v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "described-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2D(x, pool_size=(2,2), strides=(1,1), fn=np.max):\n",
    "    xm, xn = x.shape \n",
    "    pm, pn = pool_size \n",
    "    sm, sn = strides\n",
    "    \n",
    "    ym, yn = (xm-pm+1) // sm, (xn-pn+1) // sn\n",
    "\n",
    "    y = np.zeros((ym, yn))\n",
    "    \n",
    "    ii = 0\n",
    "    for i in range(0, xm-pm+1, sm):\n",
    "        jj = 0\n",
    "        for j in range(0, xn-pn+1, sn):\n",
    "            y[ii,jj] = fn(x[i:i+pm,j:j+pn])\n",
    "            jj += 1\n",
    "        ii += 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "residential-realtor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.36715236  0.09317793]\n",
      " [-0.36715236 -0.06301992]]\n",
      "[[0.98810509]]\n",
      "[[-0.92430295 -0.55469247 -0.59627284]\n",
      " [ 0.98810509 -0.64934654  0.29590853]\n",
      " [ 1.21270553  0.98248372 -0.38071894]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(3,3)\n",
    "b = pool2D(x, strides=(2,2))\n",
    "print(a)\n",
    "print(b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "exceptional-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(features, pool_size=(2,2), strides=(2,2)):\n",
    "    \n",
    "    px, py = pool_size\n",
    "    sm, sn = strides\n",
    "    width, height, chans = features.shape \n",
    "    \n",
    "    m, n = (width - px + 1) // sm, (height - py + 1) // sn\n",
    "    \n",
    "    features_ = np.zeros((m, n, chans))\n",
    "\n",
    "    # Note that we're not changing the number of features\n",
    "    for chan in range(chans):\n",
    "        features_[:,:,chan] = pool2D(features[:,:,chan], pool_size, strides)\n",
    "    \n",
    "    return features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "seasonal-burton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.3011235 , -0.24245605]]])"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling(feature_maps[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-prior",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-engine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9eb3d55570fa83a5d0e75ab0fc9e29d7692aa2022c5c86ae3b4c36003072d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
