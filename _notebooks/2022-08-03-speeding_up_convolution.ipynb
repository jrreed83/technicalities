{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naked-genre",
   "metadata": {},
   "source": [
    "# Speeding up Convolution\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: [jax, convolution]\n",
    "- hide: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-signal",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-hearts",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "For now, I only need numpy and tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "transparent-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-capture",
   "metadata": {},
   "source": [
    "## Implementation from First Principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "white-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_image(image, filters, strides):\n",
    "    \n",
    "    xm, xn, _  = image.shape \n",
    "    \n",
    "    km, kn, ni, no = filters.shape \n",
    "    \n",
    "    \n",
    "    sm, sn = strides\n",
    "    ym, yn = 1 + ((xm - km)//sm), 1 + ((xn - kn)//sn) \n",
    "    y = np.zeros((ym, yn, no))\n",
    "\n",
    "    for iy, ix in enumerate(range(0, xm-km+1, sm)):\n",
    "        for jy, jx in enumerate(range(0, xn-kn+1, sn)):\n",
    "            # Apply each output filter and bias term to this chunk\n",
    "            chunk = image[ix:ix+km,jx:jx+kn,:]\n",
    "            for channel in range(no):\n",
    "                y[iy,jy,channel] = np.sum(filters[:,:,:,channel] * chunk)\n",
    "            \n",
    "    return y\n",
    "\n",
    "def filter_images_v1(batch, filters, biases, strides):\n",
    "    outputs = [filter_image(image, filters, strides) for image in batch]\n",
    "    outputs = np.array(outputs)\n",
    "    outputs = outputs + biases\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sapphire-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_images_v2(images, filters, biases, strides):\n",
    "    \n",
    "    batch_size, xm, xn, _  = images.shape \n",
    "    \n",
    "    km, kn, _, num_filters = filters.shape \n",
    "    \n",
    "    \n",
    "    sm, sn = strides\n",
    "    ym, yn = 1 + ((xm - km)//sm), 1 + ((xn - kn)//sn) \n",
    "    y = np.zeros((batch_size, ym, yn, num_filters))\n",
    "\n",
    "    # convolution step\n",
    "    for iy, ix in enumerate(range(0, xm-km+1, sm)):\n",
    "        for jy, jx in enumerate(range(0, xn-kn+1, sn)):\n",
    "            # Apply each output filter and bias term to this chunk\n",
    "            chunk = images[:,ix:ix+km,jx:jx+kn,:]\n",
    "            for channel in range(num_filters):\n",
    "                y[:,iy,jy,channel] = np.sum(filters[:,:,:,channel] * chunk, axis=(1,2,3))\n",
    "                \n",
    "    # add bias\n",
    "    y += biases        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "natural-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keras = tf.keras.layers.Conv2D(\n",
    "    filters=4, \n",
    "    kernel_size=(4, 4), \n",
    "    strides=(1,1), \n",
    "    bias_initializer='he_uniform', \n",
    "    padding='valid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "public-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.randn(32,28,28,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alleged-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_keras = layer_keras(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outside-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters, biases = layer_keras.get_weights()\n",
    "strides = layer_keras.strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "practical-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_v1 = filter_images_v1(inputs, filters, biases, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "convenient-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_v2 = filter_images_v2(inputs, filters, biases, strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-paris",
   "metadata": {},
   "source": [
    "To check that the Keras output and numpy outputs are approximately equal, I make sure that the absolute error is below a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "combined-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(outputs_keras,outputs_v1, atol=1e-6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "married-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(outputs_keras,outputs_v2, atol=1e-6)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-hepatitis",
   "metadata": {},
   "source": [
    "Although the outputs are about the same, the Keras version runs much faster, as the following benchmarks show.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alpha-librarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381 ms ± 6.39 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "filter_images_v1(inputs, filters, biases, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unique-tradition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.3 ms ± 596 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "filter_images_v2(inputs, filters, biases, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "grateful-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19 ms ± 354 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "layer_keras(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-frame",
   "metadata": {},
   "source": [
    "### Using numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "loving-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_images_v3(images, filters, biases, strides):\n",
    "    \n",
    "    batch_size, xm, xn, _  = images.shape \n",
    "    \n",
    "    km, kn, num_input_channels, num_filters = filters.shape \n",
    "    \n",
    "    \n",
    "    sm, sn = strides\n",
    "    ym, yn = 1 + ((xm - km)//sm), 1 + ((xn - kn)//sn) \n",
    "    y = np.zeros((batch_size, ym, yn, num_filters))\n",
    "\n",
    "    # convolution step\n",
    "    for iy, ix in enumerate(range(0, xm-km+1, sm)):\n",
    "        for jy, jx in enumerate(range(0, xn-kn+1, sn)):\n",
    "            # Apply each output filter and bias term to this chunk\n",
    "            chunk = images[:,ix:ix+km,jx:jx+kn,:]\n",
    "            for output_chan in range(num_filters):\n",
    "                for item in range(batch_size):\n",
    "                    tmp = 0.0\n",
    "                    for h in range(km):\n",
    "                        for w in range(kn):\n",
    "                            for input_chan in range(num_input_channels):\n",
    "                                tmp += chunk[item, h, w, input_chan] * filters[h, w, input_chan, output_chan]\n",
    "                    y[item,iy,jy,output_chan] = tmp\n",
    "                \n",
    "    # add bias\n",
    "    y += biases        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "medium-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_v3 = filter_images_v3(inputs, filters, biases, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "technological-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(outputs_keras,outputs_v3, atol=1e-6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "central-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.02 s ± 60.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "filter_images_v3(inputs, filters, biases, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "worst-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "jitted_filter_images_v3 = numba.jit(filter_images_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "creative-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "jitted_outputs_v3 = jitted_filter_images_v3(inputs, filters, biases, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "desirable-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(outputs_keras,jitted_outputs_v3, atol=1e-6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afraid-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.65 ms ± 331 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "jitted_filter_images_v3(inputs, filters, biases, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-operator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9eb3d55570fa83a5d0e75ab0fc9e29d7692aa2022c5c86ae3b4c36003072d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
